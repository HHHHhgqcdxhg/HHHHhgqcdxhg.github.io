<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《shader入门精要》笔记-第八章-透明效果]]></title>
    <url>%2Fshader-r-alpha-effect%2F</url>
    <content type="text"><![CDATA[Unity中,有两种方式实现透明效果: 一种是透明度测试(Alpha Test),这种方法无法得到真正的半透明效果;另一种方法是透明度混合(Alpha Blending) 对于不透明物体,不考虑渲染顺序也能得到正确的排序结果,这是由于强大的深度缓冲(depth-buffer,也称z-buffer)的存在.在实时渲染中,深度缓冲是用于解决可见性问题的,它会解决哪些物体的哪些部分会被渲染在前面,哪些部分会被遮挡. 如果想要实现透明度效果,需要关闭深度写入. 透明度测试和透明度混合的原理如下: 透明度测试 采用一种”极其霸道”的机制,只要一个片元的透明度不满足条件(通常是小于某个阈值),那么它对应的片元就会被舍弃.被舍弃的片元将不会再做任何处理,也不会对颜色缓冲区造成影响.透明度测试是不需要关闭深度写入的,它和其他不透明物体最大的不同在于它会根据透明度舍弃一些片元.虽然简单,但其产生的效果会很极端:要么完全透明,要么不透明. 透明度混合 这种方法可以得到真正的半透明的效果.他会使用当前片元的透明度作为混合因子,与已经存储到颜色缓冲中的颜色进行混合,得到新的颜色.但是,透明度混合需要关闭深度写入,但没有关闭深度测试,这意味着如果使用透明度混合去渲染一个片元的话时,还是会比较它和当前缓冲区中的深度值.也就是说,对于透明度混合来说,深度缓冲是只读的. 渲染顺序关闭深度写入很重要使用透明度混合时,如果不关闭深度写入:如果一个半透明表面背后的表面本是可以透过前面的表面被我妈看到的,但由于深度测试时判断结果是前面的半透明表面距离摄像机更近,导致后面的表面将会被剔除,我们无法透过半透明表面看到后面的物体了.但是,我们破坏了深度缓冲的工作机制,而这是一个非常非常糟糕的事情,尽管我们不得不这样做: 关闭深度写入导致渲染顺序变得非常重要 不同的渲染顺序会得到的结果假设场景里有两个物体:A和B,其中A是半透明物体,B是不透明物体,如图所示 第一种情况:先渲染B,再渲染A 由于不透明物体开启了深度测试和深度写入,而因此我们的深度缓存中没有任何有效数据,因此B首先会写入颜色缓冲和深度缓冲.随后我们渲染透明物体A,仍会进行深度测试,而我们发现A比B距离摄像头更近,所以我们会使用A的带透明度颜色和B的颜色进行混合,得到正确的半透明效果 第二种情况:先渲染A,再渲染B 渲染A时,深度缓冲中没有任何有效数据,因此A直接写入颜色缓冲.但不会写入深度缓冲.等渲染B时,进行深度测试的时候,深度缓冲中没有任何有效数据,会直接覆盖A的颜色,从视觉上来看,B出现在了A的前面,而这是错误的. 因此,渲染引擎一般都会对物体进行排序,再渲染.常见方法是: 先渲染所有不透明物体,并对他们开启深度测试和深度写入; 再把半透明物体按它们距离摄像机的远近排序,然后按照从后往前的顺序渲染这些半透明物体,并开启它们的深度测试(但关闭深度写入); 但是,这种方法仍然存在问题:第二步中的渲染顺序,是依靠距离摄像机的深度判断的,而深度缓冲中的值其实是像素级别的,但是我们需要对物体级别进行排序.如图,会得到3个物体循环的情况.尽管总有一些情况打乱我们的阵脚,但由于上述方法足够有效且容易实现,因此大多数游戏引擎都选用的这种方法. Unity Shader的渲染顺序Unity为解决渲染问题提供了渲染队列(render queue)这一方案.我们可以使用Subshader的Queen标签来决定我们的模型将归于哪个渲染队列.Unity在内部使用了一系列整数索引来表示每个渲染队列,索引号越小就越先被渲染.在Unity5中,Unity提前定义了5个渲染队列. 名称 队列索引号 描述 Background 1000 背景 Geometry 2000 默认渲染队列,大多数物体使用这个队列,不透明物体使用这个队列. AlphaTest 2450 需要透明度测试的物体使用这个队列.在Unity5中它从Geometry队列中被单独分出来,这是因为在所有不透明物体轩然之后再渲染它们更高效. Transparent 3000 这个队列中的物体会在所有Geometry和AlphaTest物体渲染后,再按从后往前的顺序进行渲染.任何使用了透明度混合(例如关闭了深度写入的Shader)的物体都应该使用该队列(???) Overlay 4000 该队列用于实现一些叠加效果.任何需要在最后渲染的物体都应该使用该队列 因此,我们想要通过透明度测试实现透明效果,代码中应该包含类似下面的代码: 123456SubShader &#123; Tags&#123;"Queue" = "AlphaTest"&#125; Pass&#123; // ...... &#125;&#125; 如果我们想通过透明度混合来实现透明效果,代码中应该包含类似下面的代码: 1234567SubShader &#123; Tags&#123;"Queue" = "Transparent"&#125; Pass&#123; ZWrite Off // ...... &#125;&#125; 其中,ZWrite Off用于关闭深度写入.我们可以把它写在Pass或SubShader中. 透明度测试目测用的不多,先不看 透明度混合会使用当前片元的透明度作为混合因子,与已经存储在颜色缓冲中的颜色进行混合,得到新的颜色. 为了进行混合,我们需要使用Unity提供的混合命令–Blend.Blend是Unity提供的设置混合模式的命令.想要实现半透明效果就要把当前自身的颜色和已经存在于颜色缓冲中的颜色进行混合,混合时使用的函数就是由该指令决定的. 语义 描述 Blend Off 关闭混合 Blend SrcFactor DstFactor 开启混合,并设置混合因子.片元颜色会乘以SrcFactor,而已存在于颜色缓冲区的颜色会乘以DstFactor,然后把两者相加存入缓存. Blend SrcFactor DstFactor, SrcFactorA DstFactorA 和上面几乎一样,只是使用不同因子来混合透明通道 BlendOp BlendOption 并非是把源颜色和目标颜色简单相加后混合,而是使用BlendOption对它们进行其他操作 在本节中我们使用第二种语义来混合,需要注意的是,这个命令在设置混合因子的同时也开启了混合模式. 实践: 透明度混合1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// Upgrade NOTE: replaced '_Object2World' with 'unity_ObjectToWorld'Shader "Custom/8.4"&#123; Properties &#123; _Color ("Color", Color) = (1,1,1,1) _MainTex ("Albedo (RGB)", 2D) = "white" &#123;&#125; // AlphaScale用来控制整体透明度 _AlphaScale("Alpha Scale",Range(0,1)) = 1 &#125; SubShader &#123; // Queue标签指定队列 // RenderType标签设置为Transparent,用来指明该Shader是一个使用了透明度混合的Shader.RenderType标签通常被用于着色器替换功能. // IgnoreProject标签设为True,意味着整个Subshader不受投影器(Projectors)影响. Tags &#123; "Queue"="TransParent" "IgnoreProject"="True" "RenderType"="Transparent" &#125; Pass&#123; // 把LightMode标签设为ForwardBase,是为了让Unity能够按前向渲染路径的方式为我们正确提供各个光照变量. Tags &#123;"LightMode"="ForwardBase"&#125; // 关闭深度写入 ZWrite Off // 设置混合模式 Blend SrcAlpha OneMinusSrcAlpha CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Color; sampler2D _MainTex; float4 _MainTex_ST; fixed _AlphaScale; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; &#125;; struct v2f&#123; float4 pos : SV_POSITION; float3 worldNormal : TEXCOORD0; float3 worldPos : TEXCOORD1; float uv : TEXCOORD2; &#125;; v2f vert(a2v v)&#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.worldNormal = UnityObjectToWorldNormal(v.normal); o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz; o.uv = TRANSFORM_TEX(v.texcoord, _MainTex); return o; &#125; fixed4 frag(v2f i) : SV_TARGET&#123; fixed3 worldNormal = normalize(i.worldNormal); fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos)); fixed4 texColor = tex2D(_MainTex, i.uv); fixed3 albedo = texColor.rgb * _Color.rgb; fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo; fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(worldNormal, worldLightDir)); // alpha的值 return fixed4(ambient + diffuse,texColor.a * _AlphaScale); &#125; ENDCG &#125; &#125; FallBack "Diffuse"&#125; 当模型自身有复杂的遮挡关系或包含了复杂的非凸网格的时候,就会有各种各样因为排序错误而产生的错误的排序效果. 开启深度写入的半透明效果上面的问题都是由于关闭了深度写入造成的,因为这样我们无法对模型进行像素级别的深度排序.这是,我们可以想办法重新利用深度写入,让模型可以想半透明物体一样进行淡入淡出(淡入淡出什么鬼???).这就是下面的内容. 对于上面的问题,一种解决方法是使用两个Pass来渲染模型:一个Pass开启深度写入,但不输出颜色,它的目的仅仅是为了把该模型写入深度缓冲中;第二个Pass进行正常的透明度混合,由于上一个Pass已经得到了逐像素的正确的深度信息,该Pass就可以按照像素级别的深度排序的结果进行透明渲染.但这种方法的缺点在于,多使用一个Pass会对性能造成一定的影响. 代码只需要在上面的那份代码中新加一个Pass即可,加在原Pass的上面 1234Pass&#123; ZWrite On ColorMask 0&#125; ColorMask用于设置颜色通道的写掩码(write mask),它的语义如下: ColorMask RGB | A | 0 | 其他任何R, G, B, A的组合 当ColorMask设为0时,意味着该Pass不写入任何颜色通道,即不会输出任何颜色. ShaderLab的混合命令上面已经用了Blend命令进行混合,实际上混合还有其他很多用处,不仅仅是透明度混合. 混合的原理当片元着色器产生一个颜色的时候,可以选择与颜色缓存中的颜色进行混合,这样一来,混合就和两个操作数有关:源颜色(source color)和目标颜色(destination color). 源颜色,用S表示,指的是片元着色器产生的颜色值;目标颜色,用D表示,指的是从颜色缓冲中读取到的颜色值.对它们进行混合后得到输出颜色,用O表示,它会重新写入到颜色缓存中. 需要注意的是,当我们谈及混合中的源颜色, 目标颜色和输出颜色时,他们都包含了RGBA四个通道,而并非仅仅的RGB通道. 开启混合在Unity中,当我们使用Blend(Blend Off除外)命令时,除了设置混合状态外也开启的混合. 混合的等式和参数混合是一个逐片元的操作,而且它是不可编程的,但是是高度可配置的.我们可以设置混合时使用的运算操作,混合因子等来影响混合. 从源颜色S和目标颜色D得到输出颜色O必须适用一个等式来计算,这个等式叫做混合等式(Blending equation).当进行混合时,我们需要使用两个混合等式,一个用于混合RGB通道,一个用于混合A通道.当设置混合状态时,我们实际上设置的是混合等式中的操作和因子在默认情况下,混合等式使用的操作都是加操作(我们也可以使用其他操作),我们只需要再设置一下混合因子即可.由于需要两个等式,每个等式有两个因子(一个用于和源颜色相乘,一个用于和目标颜色相乘),因此一共需要4个因子.下面是ShaderLab中设置混合因子的命令 命令 描述 Blend SrcFactor DstFactor 开启混合,并设置混合因子.源颜色会乘以SrcFactor,而目标颜色会乘以DstFactor,然后将两者相加后存入颜色缓冲中 Blend SrcFactor DstFactor,SrcFactorA DstFactor A 和上面几乎一样,只是使用不同因子来混合透明通道. 第一个命令只提供了两个因子,这意味着使用同样混合因子来混合RGB通道和A通道,即此时SrcFactorA等于SrcFactor, DstFactorA等于DstFactor. 这些混合因子的值可以取以下: 参数 描述 One 因子为1 Zero 因子为0 SrcColor 因子为源颜色值.当用于RGB通道的混合等式时,使用SrcColor的RGB分量作为混合因子;当用于A通道混合等式时,使用SrcColor的A分量作为混合因子. SrcAlpha 因子源颜色的透明度值(A通道) DstColor 因子为目标颜色值.当用于RGB通道的混合等式时,使用DstColor的RGB分量作为混合因子;当用于A通道混合等式时,使用DstColor的A分量作为混合因子. DstAlpha 尹子维目标颜色值的透明度值(A通道) OneMinusSrcColor 1 - SrcColor OneMinusSrcAlpha 1 - SrcAlpha OneMinusDstColor 1 - DstColor OneMinusDstAlpha 1 - DstAlpha]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
        <tag>《shader入门精要》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《shader入门精要》笔记-第七章-基础纹理]]></title>
    <url>%2Fshader-r-standard-texture%2F</url>
    <content type="text"><![CDATA[纹理的最初目的是使用一张图片来控制模型的外观.使用纹理映射(texture mapping)技术,我们可以把一张图片”黏”在模型表面,逐纹素(texel)地控制模型的颜色 在美工人员建模的时候,通常会在建模软件中利用纹理展开技术把纹理映射坐标(texture-mapping coordinates)存储在每个顶点上. 单张纹理实践12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788Shader "Custom/7.1"&#123; Properties &#123; _Color ("Color Tint", Color) = (1, 1, 1, 1) // 声明一个2D纹理 _MainTex ("Main Tex", 2D) = "white" &#123;&#125; _Specular ("Specular", Color) = (1, 1, 1, 1) _Gloss ("Gloss", Range(8.0, 256)) = 20 &#125; SubShader &#123; Pass &#123; Tags &#123; "LightMode"="ForwardBase" &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Color; sampler2D _MainTex; // _MainTex的名字不是随意起的,在Unity中我们使用纹理名_ST来声明某个纹理的属性. // 其中ST是缩放(scale)和平移(translation)的缩写. // 可以在材质面板的纹理属性调整这些值控制材质的平移和缩放. float4 _MainTex_ST; fixed4 _Specular; float _Gloss; struct a2v &#123; float4 vertex : POSITION; float3 normal : NORMAL; // 会把第一组纹理存储到该变量中 float4 texcoord : TEXCOORD0; &#125;; struct v2f &#123; float4 pos : SV_POSITION; float3 worldNormal : TEXCOORD0; float3 worldPos : TEXCOORD1; float2 uv : TEXCOORD2; &#125;; v2f vert(a2v v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.worldNormal = UnityObjectToWorldNormal(v.normal); o.worldPos = mul(unity_ObjectToWorld, v.vertex).xyz; // 使用纹理缩放和偏移属性对顶点纹理坐标进行变换 o.uv = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw; // 或使用unity的内置函数 // o.uv = TRANSFORM_TEX(v.texcoord, _MainTex); return o; &#125; fixed4 frag(v2f i) : SV_Target &#123; fixed3 worldNormal = normalize(i.worldNormal); fixed3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos)); // 用tex2D对纹理进行采样 // 第一个参数是需要被采样的纹理,第二个参数是float2类型的纹理坐标 // 返回计算得到的纹素值 fixed3 albedo = tex2D(_MainTex, i.uv).rgb * _Color.rgb; fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo; fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(worldNormal, worldLightDir)); fixed3 viewDir = normalize(UnityWorldSpaceViewDir(i.worldPos)); fixed3 halfDir = normalize(worldLightDir + viewDir); fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(worldNormal, halfDir)), _Gloss); return fixed4(ambient + diffuse + specular, 1.0); &#125; ENDCG &#125; &#125; FallBack "Specular"&#125; 纹理的属性Texture Type书上讲的TextureType好像过时了,现在是这样的: 这里使用最普通的texture,在后面的法线纹理一节,我们会使用Normal map类型,在后面的章节中,我们还会看到Cubemap等高级纹理类型.我们之所以要为纹理选择合适的类型,是因为只有这样才会让Unity知道我们的意图,为Unity Shader传递正确的纹理,并在一些情况下让Unity对该纹理进行优化 Alpha Source如果选择了From Gray Scale,那么透明通道的值将会由每个像素的灰度值生成.关于透明效果会在第8章讲到 Wrap Mode当纹理坐标超过[0, 1]返回后将会如何被平铺.Repeat下,纹理将会重复.Clamp下将会对纹理进行截取. Filter Mode决定了当纹理由于变换而产生拉伸时将会采用哪种滤波模式.Filter Mode支持三种模式: Point, Bilinear, Trilinear.它们得到的图片滤波效果会依次提升,但需要消耗的性能也依次增大纹理滤波会影响放大或缩小纹理时得到的图片的质量.纹理的缩小过程比放大更复杂一些.缩小时,原纹理中的多个像素将会对应一个目标像素.纹理缩小更加复杂的原因在于我们往往需要处理抗锯齿问题,一个最常使用的方法就是使用多级渐远纹理(mipmapping)技术.多级渐远纹理技术将原纹理提前用滤波处理来得到很多更小的图像,形成一个图像金字塔,每一层都是对上一层图像降采样的结果.这样在实时运行时,就可以快速得到结果像素.例如当摄像机较远的时候,可以直接使用较小的纹理.缺点是需要使用一定空间用于存储这些多级渐远纹理,通常会多占33%的内存空间.在Unity中,我们可以在纹理导入面板中,首先将texture type选择成advanced,再勾选Generate Mip Maps即可开启多级渐远纹理技术. 这张图是,从一个倾斜角度观察一个网格结构的地板时,使用不同的Filter Mode(同时也使用了多级渐远纹理技术)得到的效果. 在内部实现上,Point模式使用了最邻近(nearest neighbor)滤波.在放大或缩小时,它的采样像素数目通常只有一个,因此图像看起来可能会有像素风格的效果. 而Bilinear滤波则使用了线性滤波,对于每个像素,它会找到四个临近像素,然后对它们进行线性插值混合后得到最终像素,因此图像看起来模糊了. 而Trilinear滤波几乎是和Bilinear一样的,只是Trilinear还会在多级渐远纹理之间进行了混合.如果一张纹理没有使用多级渐远纹理技术,那么Trilinear得到的结果就和Bilinear的完全一样了. 通常,我们选择Bilinear滤波格式.需要注意的是,有时我们不希望纹理看起来是模糊的,例如一些类似棋盘的纹理,我们希望它是像素风的,这时我们可能会选用Point模式. 纹理的最大尺寸和纹理模式当我们在不同平台发布游戏时,需要考虑目标平台的纹理尺寸和质量问题.Unity允许我们为不同目标平台选择不同的分辨率.如果导入的纹理大小超过了Max Texture Size的设置值,那么Unity将会把该纹理缩放为这个最大分辨率.理想情况下,导入的纹理可以是非正方形的,单长宽应该是2的幂.如果使用了非2的幂的大小的纹理,那么这些纹理往往会占用更多的内存空间,而且CPU读取该纹理的速度也会下降.有一些平台甚至不支持这种NPOT纹理,这时Unity在内部会把它缩放成最近的2的幂大小. 而Format则决定了Unity内部使用哪种格式来存储该纹理.如果我们将Texture Type设置为Advanced,那么会有更多的Format供我们选择. 凹凸映射凹凸映射的目的是使用一张纹理来修改模型表面的法线,以便模型提供更多的细节.这种方法不会真的改变顶点位置,只是是模型看起来凹凸不平 高度纹理使用一张高度图来实现凹凸映射高度图中存储的是强度值(intensity),它用于表示模型表面局部的海拔高度. 颜色越浅表明该位置的表面越向外凸起,越深表明该位置的表面越向里凹. 这种方法的优点是比较直观.我们可以从高度图明确的知道一个模型表面的凹凸情况.缺点是计算更加复杂,在实时计算中不能直接得到表面法线,而是由像素的灰度值计算而得.因此需要消耗更多的性能. 法线纹理法线纹理中存储的是表面的法线方向.由于法线方向的分量范围在[-1, 1],而像素的分量在[0, 1],因此我们需要做一个映射,通常使用的映射是: pixel = (normal + 1)/2 这要求我们在Shader中对法线纹理进行纹理采样后,还需要对结果进行一次反映射的过程,以得到原先的法线方向.反映射的过程实际就是使用上面映射函数的逆函数: normal = pixwl * 2 - 1 由于方向是相对于坐标空间来说的,那么法线纹理存在哪个坐标空间中呢? 模型空间的法线纹理和切线空间的法线纹理模型空间的法线纹理object-space normal map将修改后的模型空间的表面法线存储在一张纹理中. 切线空间的法线纹理tangent-space normal space对于模型的每个顶点,他都有一个属于自己的切线空间.这个切线空间的原点就是顶点本身,而z轴就是顶点的法线方向,x轴是顶点的切线方向,而y轴可由法线和切线的叉积而得,也被称为副切线(bitangent). 映射到纹理上的区别从图可以看出,模型空间下的法线纹理看起来是五颜六色的,而是因为所有法线所在的坐标空间是同一个坐标空间,即模型空间,而每个点存储的法线方向是各异的.有的是(0, 1, 0),映射后存储到纹理中就对应了RGB(0.5, 1, 0.5),浅绿色;有的是(0, -1, 0),映射后存储到纹理中对应了RGB(0.5,0,0.5)的紫色. 而切线空间下的法线纹理几乎全部都是浅蓝色.这是因为,每个发现方向所在的坐标空间是不一样的,即表面每点各自的切线空间.这种法线纹理其实是存储了每个点在各自的切线空间中的法线扰动方向.也就是说,如果一个点的法线方向不变,那么它在它的切线空间中,新法线方向就是z轴方向,即(0,0,1),经过映射后存储在纹理中就对应了RGB(0.5, 0.5, 1)的浅蓝色. 如何选择实际上,法线本身存储在哪个空间都是可以的,但问题是,我们的目的是计算光照而非单纯的计算法线.而选择哪个空间,意味着我们需要把不同的信息转换到相应的坐标系中.例如,如果选择了切线空间,我们需要把从法线纹理中得到的法线方向从切线空间转换到世界空间或其他空间中. 总体来说,用模型空间来存储法线的优点如下: 实现简单,更佳直观 我们甚至不需要模型原始的法线和切线等信息,也就是说,计算更少.生成它也很简单.而如果要生成切线空间下的法线纹理,由于模型的切线一般是和UV方向相同,因此想要得到效果比较好的法线映射就要求纹理映射也是连续的 边界平滑 在纹理坐标的缝合处和尖锐的边角部分,可见的突变(缝隙)较少.这是因为模型空间下的法线纹理存储的是统一坐标系下的法线信息.因此在边界上通过插值得到的法线可以平滑变换.而切线空间下的法线纹理中的法线信息是依靠纹理坐标的方向得到的,可能会在边缘处或尖锐部分造成更多的可见缝合现象 但使用切线空间有更多优点: 自由度很高. 模型空间下的法线纹理记录的是绝对的法线信息,仅可用于创建它时的那个模型,而应用到其他模型上效果就完全错误了.而切线空间下的法线纹理记录的是相对法线信息,即便把该纹理应用到一个完全不同的网格上,也可以得到一个合理的效果. 可进行UV动画. 比如我们可以移动一个纹理的UV坐标来实现一个凹凸移动的效果,但使用模型空间下的法线纹理会得到完全错误的结果.这种UV动画经常在水或者火山熔岩这种类型的物体上会经常用到. 可压缩 由于切线空间下的法线纹理中法线z方向总是正方向,因此我们可以仅存储XY方向,而推导出Z方向.而模型空间下的法线纹理由于每个方向都是可能的,因此必须存储3个方向的值不可压缩. 实践实践 : 在切线空间下计算光照模型在片元着色器中通过纹理采样得到切线空间下的法线,然后再与切线空间下的视角,光照方向进行计算,得到最终的光照效果.为此,我们需要在顶点着色器中把视角方向和光照方向从模型空间变换到切线空间中.即我们需要知道模型空间到切线空间的变换矩阵.这个矩阵的逆矩阵,即从切线空间变换到模型空间的变换矩阵,是很容易求得的: 我们在顶点着色器中按切线(x轴),副切线(y轴),法线(z轴)的顺序按列排列即可得到(数学原理见4.6.2节).在4.6.2节我们已经知道,如果一个变换仅存在旋转和平移变换,那么这个矩阵的转置矩阵就等于它的逆矩阵,而从切线空间到模型空间的变换正是符合这样的要求的变换.因此,我们把切线(x轴),副切线(y轴),法线(z轴)的顺序按行排列(因为转置了),即可得到模型空间到切线空间的变换矩阵. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106Shader "Custom/7.1"&#123; Properties &#123; _Color ("Color Tint", Color) = (1, 1, 1, 1) _MainTex ("Main Tex", 2D) = "white" &#123;&#125; // 法线纹理的属性 // "bump"是Unity内置的法线纹理. // Bump Scale用于控制凹凸程度,当它为0时,意味着法线纹理不对光照产生任何影响 _BumpMap ("Normal Map", 2D) = "bump"&#123;&#125; _BumpScale ("Bump Scale", Float) = 1.0 _Specular ("Specular", Color) = (1, 1, 1, 1) _Gloss ("Gloss", Range(8.0, 256)) = 20 &#125; SubShader &#123; Pass &#123; Tags &#123;"LightMode" = "ForwardBase"&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Color; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _BumpMap; float4 _BumpMap_ST; float _BumpScale; fixed4 _Specular; float _Gloss; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; // 切线方向赋给tangent float4 tangent : TANGENT; float4 texcoord : TEXCOORD0; &#125;; struct v2f&#123; float4 pos : SV_POSITION; float4 uv : TEXCOORD0; float3 lightDir : TEXCOORD1; float3 viewDir : TEXCOORD2; &#125;; v2f vert(a2v v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); // uv的xy分量存储_MainTex的纹理坐标 // zw分量存储_BumpMap的纹理坐标 // 在回忆一下,_Name_ST的xy代表的是缩放值,zw代表偏移值 o.uv.zw = v.texcoord.xy * _BumpMap_ST.xy + _BumpMap_ST.zw; // 实际上,_MainTex和_BumpMap使用同一组纹理坐标就行了,可以减少差值寄存器的使用数目. // o.uv.xy = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw; o.uv.xy = o.uv.zw; // 计算副切线.后面乘以v.tangent.w是决定副切线的方向 float3 binormal = cross(normalize(v.normal),normalize(v.tangent.xyz)) * v.tangent.w; // 把切线(x轴),副切线(y轴),法线(z轴)的顺序按行排列来得到模型空间到切线空间的变换矩阵rotation float3x3 rotation = float3x3(v.tangent.xyz,binormal,v.normal); // 把光照和视角方向变换到切线空间中 o.lightDir = mul(rotation,ObjSpaceLightDir(v.vertex)).xyz; o.viewDir = mul(rotation,ObjSpaceViewDir(v.vertex)).xyz; return o; &#125; fixed4 frag(v2f i) : SV_Target&#123; fixed3 tangentLightDir = normalize(i.lightDir); fixed3 tangentViewDir = normalize(i.viewDir); // 利用tex2D对_BumpMap进行采样 // 法线纹理中存储的是法线经过映射后得到的像素值,因此我们要把它们反映射回来 fixed4 packedNormal = tex2D(_BumpMap, i.uv.zw); fixed3 tangentNormal; tangentNormal = UnpackNormal(packedNormal); // 乘以凹凸度来得到xy分量. tangentNormal.xy *= _BumpScale; // 由xy向量计算z向量 tangentNormal.z = sqrt(1.0 - saturate(dot(tangentNormal.xy,tangentNormal.xy))); fixed3 albedo = tex2D(_MainTex, i.uv).rgb * _Color.rgb; fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo; fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(tangentNormal, tangentLightDir)); fixed3 halfDir = normalize(tangentLightDir + tangentViewDir); fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(tangentNormal, halfDir)), _Gloss); return fixed4(ambient + diffuse + specular, 1.0); &#125; ENDCG &#125; &#125; FallBack "Specular"&#125; 实践 : 在世界空间下计算光照模型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596Shader "Unity Shaders Book/Chapter 7/Normal Map In World Space" &#123; Properties &#123; _Color ("Color Tint", Color) = (1, 1, 1, 1) _MainTex ("Main Tex", 2D) = "white" &#123;&#125; _BumpMap ("Normal Map", 2D) = "bump" &#123;&#125; _BumpScale ("Bump Scale", Float) = 1.0 _Specular ("Specular", Color) = (1, 1, 1, 1) _Gloss ("Gloss", Range(8.0, 256)) = 20 &#125; SubShader &#123; Pass &#123; Tags &#123; "LightMode"="ForwardBase" &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Color; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _BumpMap; float4 _BumpMap_ST; float _BumpScale; fixed4 _Specular; float _Gloss; struct a2v &#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 tangent : TANGENT; float4 texcoord : TEXCOORD0; &#125;; struct v2f &#123; float4 pos : SV_POSITION; float4 uv : TEXCOORD0; float4 TtoW0 : TEXCOORD1; float4 TtoW1 : TEXCOORD2; float4 TtoW2 : TEXCOORD3; &#125;; v2f vert(a2v v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.uv.xy = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw; o.uv.zw = v.texcoord.xy * _BumpMap_ST.xy + _BumpMap_ST.zw; float3 worldPos = mul(unity_ObjectToWorld, v.vertex).xyz; fixed3 worldNormal = UnityObjectToWorldNormal(v.normal); fixed3 worldTangent = UnityObjectToWorldDir(v.tangent.xyz); fixed3 worldBinormal = cross(worldNormal, worldTangent) * v.tangent.w; // Compute the matrix that transform directions from tangent space to world space // Put the world position in w component for optimization o.TtoW0 = float4(worldTangent.x, worldBinormal.x, worldNormal.x, worldPos.x); o.TtoW1 = float4(worldTangent.y, worldBinormal.y, worldNormal.y, worldPos.y); o.TtoW2 = float4(worldTangent.z, worldBinormal.z, worldNormal.z, worldPos.z); return o; &#125; fixed4 frag(v2f i) : SV_Target &#123; // Get the position in world space float3 worldPos = float3(i.TtoW0.w, i.TtoW1.w, i.TtoW2.w); // Compute the light and view dir in world space fixed3 lightDir = normalize(UnityWorldSpaceLightDir(worldPos)); fixed3 viewDir = normalize(UnityWorldSpaceViewDir(worldPos)); // Get the normal in tangent space fixed3 bump = UnpackNormal(tex2D(_BumpMap, i.uv.zw)); bump.xy *= _BumpScale; bump.z = sqrt(1.0 - saturate(dot(bump.xy, bump.xy))); // Transform the narmal from tangent space to world space bump = normalize(half3(dot(i.TtoW0.xyz, bump), dot(i.TtoW1.xyz, bump), dot(i.TtoW2.xyz, bump))); fixed3 albedo = tex2D(_MainTex, i.uv).rgb * _Color.rgb; fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz * albedo; fixed3 diffuse = _LightColor0.rgb * albedo * max(0, dot(bump, lightDir)); fixed3 halfDir = normalize(lightDir + viewDir); fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0, dot(bump, halfDir)), _Gloss); return fixed4(ambient + diffuse + specular, 1.0); &#125; ENDCG &#125; &#125; FallBack "Specular"&#125; :TODO 好焦躁啊,这些先留着不看… 渐变纹理]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
        <tag>《shader入门精要》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《shader入门精要》笔记-第六章-Unity中的基础光照]]></title>
    <url>%2Fshader-r-standard-lighting%2F</url>
    <content type="text"><![CDATA[光照基础我们要模拟真实的光照环境来生成一张图像,需要考虑三种物理现象: 首先,光线从光源中被发射出来 然后,光线和场景中的一些物体相交: 一些光线被物体吸收了,而另一些光线被散射到其他方向 最后,摄像机吸收了一些光,产生了一张图像 光源在光学里,我们用辐照度(irradiance)来量化光. 对于平行光来说,它的辐照度可通过计算在垂直于l的单位面积上单位时间内穿过的量来得到. 吸收和散射光线由光源发射出来后,就会与一些物体相交,通常,相交的结果有两个:散射(scattering)和吸收(absorption) 散射只改变光线的方向,但不改变光的密度和颜色.而吸收只改变光线的密度和颜色,而不改变光线的方向. 光线在物体表面经过散射后,有两种方向:一种将会散射到物体内部,这种现象被称为折射(refraction)或透射(transmission);另一种将会散射到外部,这种现象被称为反射(reflection). 对于不透明物体,折射进入物体内部的光线还会继续与内部颗粒进行相交,其中一部分光线最后会重新发射出物体表面.而另一些则会被物体吸收.那些从物体表面重新发射出的光线将具有和入射光线不同的分布和颜色. 为了区分这两种不同的散射方向,我们在光照模型中使用了不同的部分来计算它们:高光反射(specular)部分表示物体表面是如何反射光线的漫反射(diffuse)部分则表示有多少光线会被折射,吸收和散射出表面. 根据入射光线的数量和方向,我们可以计算出射光线的数量和方向,我们常用出射度(exitance)来描述它.辐照度和出射度之间只满足先行关系的,而他们之间的比值就是材质的漫反射和高光反射属性 着色着色(shading)是指,根据材质属性(如漫反射属性等),光源信息(如光源方向,辐照度等),使用一个等式去计算沿某个观察方向的出射度的过程.我们也把这个等式称为光照模型(Lighting Model).不同光照模型有不同的目的.例如一些用于描述粗糙的物体表面,一些用于描述金属表面等. BRDF光照模型我们已经了解了光线在和物体表面相交时会发生那些现象.当已知光源位置和方向,视角方向时,我们就需要知道一个表面是如何和光照进行交互的.而BRDF(Bidirectional Reflection Distribution Function)就是用来回答这些问题的. 当给定模型的一个点时,BRDF包含了对该点外观的完整的描述.在图形学中,BRDF大多使用同一个数学公式来表示,并且提供了一些参数来调整材质属性.通俗来讲,当给定入射光线和辐照度后,BRDF可以给出在某个方向上的光照能量分布.本章设计BRDF都是对真实场景进行理想化和简化后的模型.它们并不能真实地反映物体和光照之间的交互,这些光照模型被称为是经验模型. 标准光照模型标准光照模型只关心直接光照(direct light),也就是那些从光源发射出来照射到物体表面后,经过物体表面的一次反射直接进入摄像机光线.它的基本方法是,把进入摄像机内的光线分为4部分,每个部分使用一种方法来计算它的贡献度. 自发光(emissive) 这个部分用于描述当给定一个方向时,一个表面本身会向该方向发射多少辐射量.如果没有全局光照(global illuminiation)技术,这些自发光的表面并不会真的照亮物体,只是它本身看起来更亮了而已. 高光反射(specular) 这个部分用于描述当光线从光源照射到模型表面时,该表面会在完全镜面反射方向散射出多少辐射量. 漫反射(diffuse) 这个部分用于描述,当光线从光源照射到物体表面时,该表面会向每个方向散射多少辐射量. 环境光(ambient) 用于描述其他所有间接光照 环境光虽然标准光照模型的重点在于直接光照,但在真实世界中,物体也可以被间接光照(indirect light)所照亮.间接光照是指,光线通常会在多个物体之间反射,最后进入摄像机. 在标准光照模型中,我们使用环境光来近似模拟间接光照.环境光的计算非常简单,它通常是一个全局变量,场景中的所有物体都使用这个环境光 自发光光线可以直接由光源发射进入摄像机,而不需要经过其他物体的反射.标准光照模型使用自发光来计算这个部分的贡献度.它的计算也很简单,就是直接使用了材质的自发光颜色. 通常在实时渲染中,自发光的表面往往并不会照亮周围的表面,也就是说,这个物体并不会被当做是一个光源.Unity 5引入的全局光照则可以模拟这类自发光物体对周围物体的影响(详见18章) 漫反射漫反射光照是用于对那些被物体表面完全随机散射到各个方向的辐射度进行建模的.在漫反射中,视角的位置是不重要的,因为反射是完全随机的,因此可以认为在任何反射方向上的分布都是一样的.但是入射光线的角度很重要. 漫反射光照符合兰伯特定律(Lambert’s law): 反射光线的强度与表面法线和光源方向之间的夹角的余弦值成正比 高光反射这里的高光反射是一种经验模型,也就是说,它并不完全符合真实世界中的高光反射现象.他可以用于计算那些沿着完全镜面反射方向被反射的光线,这可以让物体看上去是有光泽的,例如金属材质 计算高光反射需要知道的信息比较多,如表面法线,视角方向,光源方向,反射方向等. 高光反射的数学表达式太多了,还是看书吧,书上p124 逐像素还是逐顶点在片元着色器中计算光照模型,被称作逐像素光照(per-pixel lighting)在顶点着色器中计算光照模型,被称作逐顶点光照(per-vertex lighting) 逐像素光照在逐像素光照中,我们会以每个像素为基础,得到它的法线(可以通过对顶点法线的插值得到,也可以从法线纹理中采样得到),然后进行光照模拟的计算.这种在面片之间对顶点法线进行插值的技术被称为Phone 着色(Phone Shader),也被称为Phone插值或法线插值着色技术,这不同于之前的Phone模型. 逐顶点光照也被称为高洛德着色(Gouraud Shading).在逐顶点光照中,我们在每个顶点上计算光照,然后在渲染图元内部进行线性插值,最后输出成颜色.因为顶点数目往往远小于像素数目,因此逐顶点光照的计算量往往要小于逐像素光照.但是,由于逐顶点光照依赖于线性插值来得到像素光照,因此,当光照模型中有非线性计算(入计算高光反射)时,逐顶点光照就会出问题.而且,由于逐顶点光照会在渲染图元内部对顶点颜色进行插值,这会导致渲染图元内部的颜色总是暗于顶点处的最高颜色值.这在某些情况下会产生明显的棱角, 总结标准光照模型并不完全符合真实世界中的光照现象,但由于它的易用性,计算速度和得到的效果都比较好,因此仍在被广泛使用.标准光照模型也被称为Phone光照模型或Blinn-Phong光照模型. 但这种模型也有很多局限性.首先,很多重要的物理现象无法用该光照模型表现出来,例如菲涅尔反射(Fresenel reflection).其次,该模型是各项同性(isotropic)的,也就是说,当我们固定视角和光源方向,旋转这个表面时,反射不会发生任何改变.但有些表面是各向异性(anisotropic)的,如拉丝金属,毛发等. Unity中的环境光和自发光在Shader中,我们只需通过UNITY_LIGHTMODEL_AMBIENT就可以得到环境光的颜色和强度信息. 计算自发光只需要在片元着色器输出最后的颜色之前,把材质的自发光颜色添加到输出颜色上即可. 漫反射光照模型实践: 逐顶点漫反射光照123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Shader "Custom/6.4"&#123; Properties &#123; _Diffuse("Diffuse",Color) = (1, 1, 1, 1) &#125; Subshader&#123; Pass&#123; // 使用Tags指明该Pass的光照模式 // 只有定义了正确的LightMode,我们才能得到一些Unity的内置光照变量,如后面的_LightColor0 Tags&#123;"LightMode" = "ForwardBase"&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag // 需要使用UNity中的内置光照变量,如后面的_lightColor0,还需包含Unity的内置文件Lighting.cginc #include "Lighting.cginc" fixed4 _Diffuse; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; &#125;; struct v2f&#123; float4 pos : POSITION; float3 color : COLOR; &#125;; v2f vert(a2v v)&#123; v2f o; // 将顶点坐标从模型空间变换到剪裁空间中 o.pos = UnityObjectToClipPos(v.vertex); // 通过UNITY_LIGHTMODEL_AMBIENT获得环境光部分 fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz; // 将法线变换至世界坐标空间下,并进行归一化 fixed3 worldNormal = normalize(mul(v.normal,(float3x3)unity_WorldToObject)); // 光源方向由_WorldSpaceLightPos0得到,并进行归一化 float3 worldLight = normalize(_WorldSpaceLightPos0.xyz); // 通过_LightColor0访问光源的颜色和强度信息 // saturate是Cg提供的一种函数,它的作用是把参数截取到[0, 1]的范围内. // 将 法线 与 光源方向 的 点积 与 光源的颜色 和 强度 以及 材质的漫反射颜色 相乘 得到 最终的漫反射光照部分 fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal,worldLight)); // 将环境光与漫反射光部分相加,得到最终的光照结果 o.color = ambient + diffuse; return o; &#125; fixed4 frag(v2f i) : SV_TARGET&#123; return fixed4(i.color, 1.0); &#125; ENDCG &#125; &#125; FallBack "Diffuse"&#125; 顶点着色器部分解释:在第一行,我们首先定义了返回值o.我们已经重复过很多次,顶点着色器最基本的任务就是把顶点位置从模型空间转换到剪裁空间中.书上比较过时的方法是 使用Unity内置的 模型世界投影矩阵 UNITY_MATRIX_MVP 来完成这样的坐标变换.实际打代码的时候,编辑器顶部出现了一行 1// Upgrade NOTE: replaced 'mul(UNITY_MATRIX_MVP,*)' with 'UnityObjectToClipPos(*)' ,然后对应部分的代码也被改了. 接下来是真正计算漫反射光照的部分.回忆一下,为了计算漫反射我们需要知道4个参数.在前面的步骤中,我们已经知道了材质的漫反射颜色_Diffuse以及顶点法线v.normal.还需要知道光源的颜色和强度信息以及光源方向. 通过Unity提供的内置变量 _LightColor0 来访问该Pass处理光源的颜色和强度信息 通过Unity提供的内置变量 _WorldSpaceLightPos0 得到光源方向 需要注意的是,这里对光源方向的计算不具有通用性.当前场景下,我们假设只有一个光源且其类型是平行光. 如果场景下有多个光源并且类型是点光源等其他类型,直接使用_WorldSpaceLightPos0就不能得到正确的结果. 计算光源方向与法线的点积时,只有两者处于统一坐标空间下,他们的点积才有意义.于是在这里我们选用世界空间. 在得到世界空间下的法线和光源方向后,我们需要对它们进行归一化操作;在得到它们的点积的结果后,我们需要防止这个结果为负值.为此,我们选用saturate函数.saturate函数是Cg提供的一种函数,它的作用是可以把参数截取到[0, 1]范围内.再将 法线 与 光源方向 的 点积 与 光源的颜色 和 强度 以及 材质的漫反射颜色 相乘 得到 最终的漫反射光照部分 最后,将环境光与漫反射光部分相加,得到最终的光照结果 思考:法线 与 光源方向 的 点积 与 光源的颜色 和 强度 以及 材质的漫反射颜色 相乘 的意义我的理解: 法线 与 光源方向 的 点积 的结果,应该就是光源方向在法线方向上的投影值.这个投影值的意义是漫反射的强度.顶点法线正对入射光线,漫反射效果最强.顶点法线与入射光线的夹角大于90度,则完全没有漫反射效果.之后再以强度与光源颜色和材质颜色相乘,得到漫反射颜色. 对于细分度较高的模型,逐顶点光照已经可以得到比较好的光照效果了.但对于一些细分程度较低的模型,逐顶点光照就会出现一些视觉问题.例如这里就有点锯齿 实践: 逐像素漫反射光照相较于上个人逐顶点光照,把对光照的计算从vert函数转到了frag函数. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Shader "Custom/6.4"&#123; Properties &#123; _Diffuse("Diffuse",Color) = (1, 1, 1, 1) &#125; Subshader&#123; Pass&#123; Tags&#123;"LightMode" = "ForwardBase"&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Diffuse; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; &#125;; struct v2f&#123; float4 pos : SV_POSITION; float3 worldNormal : TEXCOORD0; &#125;; v2f vert(a2v v)&#123; // vert函数中仅传递光照方向及法线方向 v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.worldNormal = mul(v.normal,(float3x3)unity_WorldToObject); return o; &#125; fixed4 frag(v2f i) : SV_TARGET&#123; // 计算在frag函数中进行 fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz; fixed3 worldNormal = normalize(i.worldNormal); fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz); fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal,worldLightDir)); fixed3 color = ambient + diffuse; return fixed4(color, 1); &#125; ENDCG &#125; &#125; FallBack "Diffuse"&#125; 逐像素光照更佳平滑但是,即使用了逐像素漫反射光照,有一个问题仍然存在:在光照无法到达的区域,模型外观通常是黑的,没有任何明暗变化,这会使模型的背光区域看起来就像一个平面一样,失去模型细节表现.实际上我们可以通过添加环境光来得到非全黑的效果,但即便这样也无法解决背光面明暗一样的缺点.为此,有一种改善技术被提出来,这就是半兰伯特(Half Lambert)光照模型 半兰伯特光照模型在上面的光照实例中使用的光照模型也被称为兰伯特光照模型,因为它符合兰伯特定于—-在平面某点漫反射光强与该反射点的法向量和入射角的余弦值成正比.半兰伯特光照模型是在原兰伯特光照模型上修改的.与原兰伯特模型相比,版兰伯特光照模型没有使用saturate函数截取法向量和光照方向的点积,而是使点积结果乘以一个值再加上一个值.通常情况下.这两个值都为0.5,通过这种方式就能把法向量和光照方向的点积的结果范围从[-1, 1]映射到[0, 1]范围内. 对于模型的背光面,原兰伯特模型中点积结果将映射到同一个值,即0处;而半兰伯特模型中,背光面也会有明暗变化. 需要注意的是,半兰伯特光照模型是没有任何物理依据的,仅仅是一个视觉加强. 球的背光面在两种光照模型下的表现: 原兰伯特光照模型 半兰伯特光照模型 高光反射光照模型基本光照模型中高光反射部分的计算公式:计算高光反射需要四个参数:入射光线的颜色和强度,材质的高光反射系数,视角方向以及反射方向.其中,反射方向可以由表面法线和光源方向计算而得. 上述计算很简单,更幸运的是,Cg提供了计算反射方向的函数:reflect. 函数: reflect(i,n)参数: i: 入射方向;n:法线.可以是float,float2,float3等. 实践: 逐顶点高光反射光照1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Shader "Custom/6.4"&#123; Properties &#123; _Diffuse("Diffuse", Color) = (1, 1, 1, 1) // 材质的高光反射颜色 _Specular("Specular", Color) = (1, 1, 1, 1) // 高光区域的大小 _Gloss("Gloss",range(8.0,256)) = 20 &#125; Subshader&#123; Pass&#123; Tags&#123;"LightMode" = "ForwardBase"&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Diffuse; fixed4 _Specular; float _Gloss; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; &#125;; struct v2f&#123; float4 pos : SV_POSITION; fixed3 color : COLOR; &#125;; v2f vert(a2v v)&#123; v2f o; // 漫反射部分 o.pos = UnityObjectToClipPos(v.vertex); fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz; fixed3 worldNormal = normalize(mul(v.normal, (float3x3)unity_WorldToObject)); fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz); fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal,worldLightDir)); // 入射光线关于法线的反射方向. // 由于Cg的reflect函数的入射方向要求是由光源指向交点处的,因此我们要把worldLightDir取反后再传给reflect函数 fixed3 reflectDir = normalize(reflect(-worldLightDir,worldNormal)); // 世界空间下的 摄像机坐标与顶点坐标相减,得到视角方向 fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - mul(unity_ObjectToWorld,v.vertex).xyz); // 根据公式和所有的四个参数,带入公式得到高光反射的光照部分. fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(saturate(dot(reflectDir,viewDir)),_Gloss); o.color = ambient + diffuse + specular; return o; &#125;; fixed4 frag(v2f i) : SV_TARGET&#123; return fixed4(i.color,1.0); &#125;; ENDCG &#125; &#125; // fallback调成Specular FallBack "Specular"&#125; 使用逐顶点的方法得到的高光效果,高光部分及其不平滑:因为高光部分的计算是非线性的,而在顶点着色器中在进行插值的过程是线性的,破坏了原计算的非线性关系. 实践: 逐片元高光反射光照12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Shader "Custom/6.4"&#123; Properties &#123; _Diffuse("Diffuse", Color) = (1, 1, 1, 1) // 材质的高光反射颜色 _Specular("Specular", Color) = (1, 1, 1, 1) // 高光区域的大小 _Gloss("Gloss",range(8.0,256)) = 20 &#125; Subshader&#123; Pass&#123; Tags&#123;"LightMode" = "ForwardBase"&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Diffuse; fixed4 _Specular; float _Gloss; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; &#125;; struct v2f&#123; float4 pos : SV_POSITION; float3 worldNormal : TEXCOORD0; float3 worldPos : TEXCOORD1; &#125;; v2f vert(a2v v)&#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.worldNormal = mul(v.normal, (float3x3)unity_WorldToObject); o.worldPos = mul(unity_ObjectToWorld,v.vertex).xyz; return o; &#125;; fixed4 frag(v2f i) : SV_TARGET&#123; fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz; fixed3 worldNormal = normalize(i.worldNormal); fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz); fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal,worldLightDir)); fixed3 reflectDir = normalize(reflect(-worldLightDir,worldNormal)); fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(saturate(dot(reflectDir,viewDir)),_Gloss); return fixed4((ambient + diffuse + specular),1.0); &#125;; ENDCG &#125; &#125; // fallback调成Specular FallBack "Specular"&#125; 将计算转移到了frag函数中. Blinn-Phong光照模型上面是Phong光照模型的实现.而Blinn模型没有使用反射方向,而是引入了一个新的矢量而Blinn模型计算高光反射的公式是理解:理解个尖儿,貌似也是个没有物理根据的经验模型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768Shader "Custom/6.4"&#123; Properties &#123; _Diffuse("Diffuse", Color) = (1, 1, 1, 1) _Specular("Specular", Color) = (1, 1, 1, 1) _Gloss("Gloss",range(8.0,256)) = 20 &#125; Subshader&#123; Pass&#123; Tags&#123;"LightMode" = "ForwardBase"&#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include "Lighting.cginc" fixed4 _Diffuse; fixed4 _Specular; float _Gloss; struct a2v&#123; float4 vertex : POSITION; float3 normal : NORMAL; &#125;; struct v2f&#123; float4 pos : SV_POSITION; float3 worldNormal : TEXCOORD0; float3 worldPos : TEXCOORD1; &#125;; v2f vert(a2v v)&#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.worldNormal = mul(v.normal, (float3x3)unity_WorldToObject); o.worldPos = mul(unity_ObjectToWorld,v.vertex).xyz; return o; &#125;; fixed4 frag(v2f i) : SV_TARGET&#123; fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz; fixed3 worldNormal = normalize(i.worldNormal); fixed3 worldLightDir = normalize(_WorldSpaceLightPos0.xyz); fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal,worldLightDir)); // 新增 fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - i.worldPos.xyz); // 新增 fixed3 halfDir = normalize(worldLightDir + viewDir); // 公式 fixed3 specular = _LightColor0.rgb * _Specular.rgb * pow(max(0,dot(worldNormal,halfDir)),_Gloss); return fixed4((ambient + diffuse + specular),1.0); &#125;; ENDCG &#125; &#125; FallBack "Specular"&#125; 效果:谔谔,总感觉区别不大…高光范围比上面大了点…]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
        <tag>《shader入门精要》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《shader入门精要》笔记-第五章-开始Unity Shader学习之旅]]></title>
    <url>%2Fshader-r-start%2F</url>
    <content type="text"><![CDATA[最简单的顶点/片元着色器顶点/片元着色器的基本结构12345678910111213141516171819202122232425262728293031323334Shader "MyShaderName"&#123; Properties&#123; // 属性 &#125; SubShader&#123; // 针对显卡A的SubShader Pass&#123; // 设置渲染状态和标签 // 开始Cg代码片段 CGPROGRAM // 该代码片段的编译指令 #pragma vertex vert #pragma fragment frag // Cg代码写在这里 // 结束Cg代码段 ENDCG // 其他设置 &#125; // 其他需要的Pass &#125; SubShader&#123; // 针对显卡B的SubShader &#125; // 上面的SubShader都失败后用于回调的Unity Shader Fallback "VertexLit"&#125; 其中最重要的是Pass语义块.我们绝大多数的代码都是写在Pass语义块中的.下面是一个实际的最简单的顶点/片段着色器 12345678910111213141516171819202122Shader "Custom/myShader"&#123; SubShader&#123; Pass&#123; CGPROGRAM // 告诉unity,vert函数包含了顶点着色器代码,frag函数包含了片段着色器代码. #pragma vertex vert #pragma fragment frag float4 vert(float4 v : POSITION) : SV_POSITION &#123; return mul(UNITY_MATRIX_MVP, v); // MVP矩阵是: 当前的模型矩阵·观察矩阵·投影矩阵,用于将顶点/方向矢量从模型空间变换到剪裁空间 &#125; fixed4 frag() : SV_Target&#123; return fixed4(1.0, 1.0, 1.0, 1.0); &#125; ENDCG &#125; &#125;&#125; vert函数里的POSITION和SV_POSITION都是Cg/HLSL中的语义(semantics),是不可省略的,它们告诉系统用户需要哪些输入值,以及用户的输出是什么.例如这里:POSITION告诉Unity,把模型顶点坐标填充到参数vSV_POSITION告诉Unity,顶点着色器的输出是剪裁空间中的顶点坐标如果没有这些语义来限定输入和输出参数的话,渲染器就完全不知道用户的输入和输出是什么,因此会得到错误的结果. 本例中的frag函数没有任何输入,它的输出是一个fixed4类型的变量,并且使用了SV_Target语音进行限定.SV_Targrt也是HLSL中的一个系统语义,它等同于告诉渲染器,把用户的输出颜色存储到一个渲染目标(render target)中,这里将输出到默认的帧缓存中. 模型数据从哪来如想要得到更多的模型数据(如顶点的纹理坐标和法线方向),我们需要为顶点着色器定义一个结构体作为输入参数. 1234567891011121314151617181920212223242526272829303132333435Shader "Custom/MyShader"&#123; SubShader&#123; Pass&#123; CGPROGRAM #pragma vertex vert #pragma fragment frag // 使用一个结构体来定义顶点着色器的输入 struct a2v&#123; // POSITION语义告诉Unity, 用模型空间的顶点坐标填充vertex变量 float4 vertex : POSITION; // NORMAL语义告诉Unity, 用模型空间的法线方向填充normal变量 float3 normal : NORMAL; // TEXCOORD0语义告诉Unity, 用模型的第一套纹理坐标填充texcoord变量 float4 texcoord : TEXCOORD0; &#125;; float4 vert(a2v v) : SV_POSITION&#123; // 使用v.vertex来访问模型空间的顶点坐标 return mul(UNITY_MATRIX_MVP, v.vertex); &#125; fixed4 frag() : SV_Target&#123; return fixed4(1.0, 1.0, 1.0, 1.0); &#125; ENDCG &#125; &#125;&#125; 在上面的代码中,我们声明了一个新的结构体a2v,它包含了顶点着色器需要的模型数据.对于顶点着色器的输入,Unity支持的语义有: POSITION, TANGENT, NORMAL, TEXCOORD0, TEXCOORD1, TEXCOORD2, TEXCOORD3, COLOR 等. 为了新建一个结构体, 我们必须使用如下格式来定义它: 12345struct StructName&#123; Type Name : Semantic; Type Name : Semantic; ......&#125; 然后,我们又修改了vert函数的输入类型为a2v. a表示应用(application),v表示顶点着色器(vertex shader),a2v的意思就是把数据从应用阶段传递到顶点着色器中. 顶点着色器和片元着色器的通信123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Shader "Custom/Myshader"&#123; SubShader&#123; Pass&#123; CGPROGRAM #pragma vertex vert #pragma fragment frag struct a2v &#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; &#125;; // 使用一个结构体来定义顶点着色器的输出 struct v2f &#123; // SV_POSITION语义告诉Unity, pos里包含了顶点在剪裁空间中的位置信息 float4 pos : SV_POSITION; // COLOR0语义可以用于存储颜色信息 fixed3 color : COLOR0; &#125; v2f vert(a2v v)&#123; // 声明输出的结构 v2f o; o.pos = mul(UNITY_MATRIX_MVP, v.vertex); // v.normal包含了顶点的法线方向, 其分量在[-1.0, 1.0] // 下面的代码将分量范围映射到了[0.0, 1.0] // 存储到o.color中传递给片元着色器 o.color = v.normal * 0.5 + float3(0.5, 0.5, 0.5); return o; &#125; fixed4 frag(v2f i) : SV_Target&#123; // 将插值后的i.color显示到屏幕上 return fixed4(i.color, 1.0); &#125; ENDCG &#125; &#125;&#125; 在上面代码中,我们定义了一个v2f结构体在顶点着色器和片元着色器之间传递信息.顶点着色器的输出结构中,必须包含一个语义为SV_POSITION的变量,否则渲染器会无法得到剪裁空间中的顶点坐标,也就无法将颜色渲染到屏幕上. 至此,我们完成了顶点着色器和片元着色器之间的通信.需要注意的是,顶点着色器是逐顶点调用的,而片元着色器是逐片元调用的,所以片元着色器的输入实际上是把顶点着色器的输出进行插值得到的结果. 如何使用属性通过材质,我们可以方便地调节Unity Shader中的参数,从而随时调整材质的效果.这些参数需要卸载Properties语义块中. 123456789101112131415161718192021222324252627282930313233343536373839404142Shader "Custom/Myshader"&#123; SubShader&#123; Pass&#123; CGPROGRAM #pragma vertex vert #pragma fragment frag // 在Cg代码中,我们需要定义一个与属性的名称和类型都匹配的变量 fixed4 _Color; struct a2v &#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; &#125;; struct v2f &#123; float4 pos : SV_POSITION; fixed3 color : COLOR0; &#125; v2f vert(a2v v)&#123; v2f o; o.pos = mul(UNITY_MATRIX_MVP, v.vertex); o.color = v.normal * 0.5 + float3(0.5, 0.5, 0.5); return o; &#125; fixed4 frag(v2f i) : SV_Target&#123; float3 c = i.color; // 使用-Color属性控制输出颜色 c *= _Color.rgb; return fixed4(c, 1.0); &#125; ENDCG &#125; &#125;&#125; 在上面的代码中,我们首先添加了Properties语义块,并在其中声明了一个属性_Color,它的类型是Color,初始值是(1.0, 1.0, 1.0, 1.0).为了在Cg代码中使用,我们还需要在Cg代码片段中提前定义一个新的变量,这个变量的名称和类型必须与Properties中的属性定义相匹配 ShaderLab属性类型 Cg变量类型 Color, Vector float4, half4, fixed4 Range, Float float, half, fixed 2D sampler2D Cube samplerCube 3D sampler3D 有时会遇到uniform 1uniform fixed4 _Color; uniform关键词是Cg中修饰变量和参数的一种修饰词,它仅仅用于提供一些关于该变量的初始值是如何指定和存储的相关信息.在Unity Shader中,uniform关键词是可以省略的(所以uniform到底是个啥啊草) Unity内置文件和变量为了方便开发者的编码过程,Unity提供了很多内置文件,这些文件包含了很多提前定义的变量,函数和宏等. 内置的包含文件包含文件(include file),是类似于C++头文件的一种文件.在Unity中,它们的文件后缀是.cginc.在编写shader时,我们可以用#include把这些文件包含进来,这样我们就可以使用Unity为我们提供的一些非常有用的变量和帮助函数.例如: 1234CDPROGRAM// ...#include "UnityCG.cginc"// ... unity\Editor\Data\CGIncludes文件夹包含了一些内置组件或功能需要的UnityShader. CDIncludes中主要的包含文件及它们的用处: 文件名 描述 UnityCG.cginc 包含了最常使用的帮助函数,宏和结构体等 UnityShaderVriables.cginc 在编译Unity Shader时,会被自动包含进来.包含了许多内置的全局变量,如UNITY_MATRIX_MVP等 Lighting.cginc 包含了各种内置的关照模型,如果包含的是表面着色器的话会自动包含进来 HLSLSupport.cginc 在编译Unity Shader时,会被自动包含进来.声明了许多跨平台编译的宏和定义 除这些之外,Unity5引入了许多新的重要的包含文件,如UnityShaderVariables.cginc, UnityStandardCore.cginc等,这些包含文件用于实现基于物理的渲染,我们会在18章再次遇到它们 UnityCG.cginc是我们最常接触的一个包含文件.它提供了很多结构体和函数方便我们编写Shader.例如,我们可以直接使用UnityCG.cginc中预定义的结构体作为顶点着色器的输入和输出. 名称 描述 包含的变量 appdata_base 可用于顶点着色器的输入 顶点位置,顶点法线,第一组纹理坐标 appdata_tan 可用于顶点着色器的输入 顶点位置,顶点切线,顶点法线,第一组纹理坐标 appdata_full 可用于顶点着色器的输入 顶点位置,顶点切线,顶点法线,四组(或更多)纹理坐标 appdata_img 可用于顶点着色器的输入 顶点位置,第一组纹理坐标 v2f_img 可用于顶点着色器的输出 裁剪空间中的位置 纹理坐标 除了结构体外,UnityCG.cginc也提供了一些常用的帮助函数 函数名 描述 float3 WorldSpaceViewDir(float4 v) 输入一个模型空间中的顶点位置,返回世界空间中从该点到摄像机的观察方向 float3 ObjSpaceViewDir(float4 v) 输入一个模型空间中的顶点位置,返回模型空间中该点到摄像机的观察方向 float3 WorldSpaceLightDir(float4 v) 仅可用于前向渲染中.输入一个模型空间中的顶点位置,返回世界空间中从该点到光源的光照方向.没有被归一化 float3 ObjSpaceLightDir(float4 v) 仅可用于前向渲染中.输入一个模型空间中的顶点位置,返回模型空间中从该点到光源的光照方向.没有被归一化 float3 UnityObjectToWorldNormal(float3 norm) 把法线方向从模型空间变换到世界空间中 float3 UnityObjectToWorldDir(float3 dir) 把方向矢量从模型空间变换到世界空间中 float3 UnityWordToObjectDir(float3 dir) 把方向矢量从世界空间变换到模型空间中 内置的变量Unity还提供了用于访问时间,光照,雾效和环境光等目的的变量.这些内置变量大多位于UnityShaderVariables.cginc中,与光照有关的内置变量还会位于Lighting.cginc, AutoLighting.cginc等文件中.后面遇到再详细讲解 Unity提供的Cg/HLSL语义语义语义就是一个赋给Shader的输入和输出的字符串,这个字符串表达了这个参数的含义.通俗地讲,这些语义可以让Shader知道从哪里读取数据,并把数据输出到哪里.语义在Cg/HLSL的Shader流水线中是不可或缺的.需要注意的是,Unity并没有支持所有语义. 通常情况下,这些输入输出变量并不需要有特别的意义.也就是说,我们可以自行决定这些变量的用途. 在DX 10之后,有一种新的语义类型,就是系统数值语义(system-value semantics).这类语义是以SV开头的,SV代表的含义就是系统数值(system-value).这些语义在渲染流水线中有特殊的含义.例如我们用SV_POSITION语义去修饰顶点着色器的输出变量pos,那么就表示pos包含了可用于光栅化的变换后的顶点坐标. 这些语义修饰的变量时不可以随意赋值的,因为流水线需要使用它们来完成特定的目的.例如渲染引擎会把用SV_POSITION修饰的变量经过光栅化后显示在屏幕上.有时会看到同一个变量在不同的Shader里面使用了不同的语义修饰.例如,一些Shader会使用POSITION而非SV_POSITION来修饰顶点着色器的输出.SV_POSITION是DirectX 10中新引入的系统数值语义,在绝大多数平台上,它和POSITION是等价的,但在某些平台(例如索尼PS4)上必须使用SV_POSITION来修饰顶点着色器的输出.否则无法让Shader正常工作. 因此,对于这些有特殊含义的变量我们最好使用SV开头的语义进行修饰. Unity支持的语义从应用阶段传递模型数据给顶点着色器时Unity支持的常用语义 语义 描述 POSITION 模型空间中的顶点位置,通常是float4类型 NORMAL 顶点法线,通常是float3类型 TANGENT 顶点切线,通常是float4类型 TEXCOORDn 该顶点的纹理坐标.通常是float2或float4类型 COLOR 顶点颜色,通常是fixed4或者float4类型 其中TEXCOORDn是指TEXCOORD0,TEXCOORD1…其中n的数目是和Shader Model有关的,例如一般在Shader Model2(即Unity默认编译到的Shader Model版本)和Shader Model3中,n等于8,而在Shader Model5中,n等于16.通常情况下,一个模型的纹理坐标数一般不超过2,我们往往只使用TEXCOORD0和TEXCOORD1.在Unity中内置的数据结构体appdata_full中,它最多使用了6个纹理坐标 从顶点着色器传递数据给片元着色器时Unity使用的常用语义 语义 描述 SV_POSITION 裁剪空间中的顶点坐标,结构体中必须包含一个用该语义修饰的变量. COLOR0 通常用于输出第一组颜色信息,但不是必须的 COLOR1 通常用于输出第二组颜色信息,但不是必须的 TEXCOORD0~TEXCOORD7 通常用于输出纹理坐标,但不是必须的 上面的语义中,除了SV_POSITION是有特殊的含义外,其他语义对变量的含义没有明确的要求.也就是说,我们可以存储任意值到这些语义描述变量中.通常,如果我们需要把一些自定义的数据从顶点着色器传递给片元着色器,一般选用TEXTURE0等 片元着色器输出时Unity支持的常用语义 语义 描述 SV_Target 输出值将会存储到渲染目标(render target)中 如何定义复杂的变量类型上面提到的语义绝大部分用于描述标量或矢量类型的变量下面的代码给出了一个使用语义来修饰不同类型的变量的例子: 1234567struct v2f&#123; float4 pos : SV_POSITION; fixed3 color0 : COLOR0; fixed4 color1 : COLOR1; half value0 : TEXCOORD0; float2 value1 : TEXCOORD1;&#125;; 关于何时使用哪些变量类型,我们会在5.7.1节给出一些建议.但需要注意的是,一个语义可以使用的寄存器只能处理4个浮点值.因此,如果我们想要定义矩阵类型,如float3X4等变量就需要使用更多的空间.一种方法是,将这些变量拆分成多个变量,例如对于float4X4的矩阵类型,我们可以拆分成4个float类型的变量,每个变量存储了矩阵中的一行数据. Debug书上P111 渲染平台的差异书上p115 Shader整洁float, half还是fixed 类型 精度 float 最高精度浮点值,通常使用32位来存储 half 中等精度浮点值,通常使用16位来存储,精度是-60,000 ~ 60,000 fixed 最低精度浮点值,通常使用11位来存储,精度是-2.0~2.0 上面的精度范围并不是绝对正确的,尤其是在不同平台和GPU上,他们的实际精度可能和上面给出的范围不一致.通常来讲. 大多数现代的桌面GPU会把所有计算都按最高的浮点精度进行计算.也就是说,float,half,fixed在这些平台上实际是等价的.这意味着我们在PC上很难看出因为half和fixed精度不同而带来的不同. 但在移动平台的GPU上,它们的确会有不同的精度范围.而且不用精度的浮点值的运算速度也会有差异.因此,我们应该确保在真正的移动平台上试验我们的Shader fixed精度实际上只在一些较旧的移动平台上有用,大多数现代GPU上,它们内部把fixed和half当成同样精度来对待. 尽管有上面的不同,单一个基本建议是,尽可能使用精度较低的类型,因为这可以优化Shader的性能,这一点在移动平台上尤其重要.从它们的大体的值域范围来看,我们可以使用 fixed类型来存储颜色和单位矢量 half存储更大的数据 最差的情况再使用float 如果我们的目标是移动平台,一定要确保在真实的手机上测试我们的Shader.关于移动平台的优化技术,更多内容见16章 规范语法在5.6.2节,我们提到了DirectX平台对Shader的语义有更加严格的要求.这意味着,如果我们要发布到DirectX平台上就需要使用更严格的语法.例如,使用和变量类型相匹配的参数数目来对变量进行初始化. 避免不必要的计算如果我们毫无节制地在Shader(尤其是片元着色器)中进行了大量计算,那么我们可能很快就会收到Unity的错误提示: temporary register limit of 8 exceeded 或 Arithmetic instruction limit of 64 exceeded; 65 arithmetic instructions needed to compileprogram 这样的错误太多是因为我们在Shader中进行了大量的运算,使得需要的临时寄存器数目或指令数目超过了当前可支持的数目.不同的Shader Target,不同的着色器阶段,我们可使用的临时寄存器和指令数目都是不同的. 通常,我们可以通过指定更高级的Shader Target来消除这些错误. 指令 描述 #pragma target2.0 默认的Shader Target等级,相当于Direct3D上的Shader Model2.0,不支持对顶点纹理的采样,不支持显式的LOD纹理采样等 #pragma target3.0 相当于Direct3D 9 上的Shader Model 3.0, 支持对顶点纹理的采样等 #pragma target4.0 相当于Direct3D 10 上的Shader Model 4.0,支持几何着色器等 #pragma target5.0 相当于Direct3D11上的Shader Model 5.0 Shader Model是由微软提出的一套规范,通俗地理解就是它们决定了Shader中各个特性和能力.这些特性和能力体现在Shader能使用的运算指令数目,寄存器个数等各个方面.Shader等级越高,Shader的能力就越大. 虽然更高级的Shader Target可以让我们使用更多的临时寄存器和运算指令,但一个更好的方法是尽可能减少Shader中的运算,或者通过预计算的方式来提供更多的数据. 慎用分支和循环语句if-else,for,while这些流程控制指令在GPU上的实现和在CPU上大不相同.在最坏的情况下,我们花在一个分支语句的时间相当于运行所有分支语句的时间.因此不提倡在Shader中使用流程控制语句. 如果我们的Shader中使用了大量的流程控制语句,那么这个Shader的性能可能会成倍下降.一个解决方法是,我们应尽量把计算向流水线上端移动.例如把片段着色器中的计算放到顶点着色器中,或者直接在CPU中进行预计算,再把结果传递给Shader. 实在要用到分支语句时: 分支判断语句中使用的条件变量最好是常数,即在Shader运行过程中不会发生变化. 每个分支中包含的操作指令尽可能少 分支嵌套层数尽可能少 不要除以0Shader中,除以0不会报错.注意.]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
        <tag>《shader入门精要》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《shader入门精要》笔记-第三章-Unity Shader 基础]]></title>
    <url>%2Fshader-r-unity-shader%2F</url>
    <content type="text"><![CDATA[UnityShader概述unity中的shaderStandard Surface Shader会产生一个包含了标准光照模型(使用了Unity5中新添加的基于物理的渲染方法,详见第18章)的表面着色器模板 Unlit Shader会产生一个不含光照(单包含雾化效果)的基本顶点/片段着色器 ImageEffect Shader为我们实现各种屏幕文件.这类Shader旨在利用GPU的并行性来进行一些与常规渲染流水线无关的计算,而不在这本书的讨论范围内(草) UnityShader的结构SubShaderSubshader中定义了一系列的Pass一级可选的状态和标签的设置. 每个Pass定义了一次完整的渲染流程,但如果pass的数目过多,往往会造成渲染性能的下降.因此,我们应尽量使用小数目的Pass. 状态和标签同样可以在Pass声明.不同的是,SubShader中的一些标签设定是特定的.也就是说,这些标签设置和Pass中使用的标签是不一样的.而对于状态设置来说,其使用的语法是相同的.但是,如果我们在SubShader中进行了这些设置,那么将会用于所有Pass 状态设置ShaderLab提供了一系列渲染状态的设置指令,这些指令可以设置显卡的各种状态.例如是否开启混合/深度测试等. 状态名称 设置指令 解释 Cull Cull Back/Front/Off 设置剔除模式.剔除背面/正面/关闭剔除 ZTest ZTest Less Greater/LEqual/GEqual/NotEqual/Always 设置深度测试时使用的函数 Zwrite ZWrite On/Off 开启/关闭深度测试 Blend Blend SrcFactor DstFactor 开启并设置混合模式 当在SubShader块中设置了这些渲染状态时,将会应用到所有Pass,如果我们不想这样,可以在Pass语义块中单独进行上面的设置. SubShader标签SubShader的标签是一个键值对,他的键和值都是字符串类型.标签结构如下: 1Tags &#123; &quot;TagName1&quot; = &quot;Value1&quot; &quot;TagName2&quot; = &quot;Value2&quot; &#125; 标签类型 说明 例子 Queue 控制渲染顺序,指定该物体属于哪一个渲染队列,通过这种方式可以保证所有的透明物体可以在所有不透明物体后面被渲染(详见第8章).我们也可以自定义使用的渲染队列来控制物体的渲染顺序 Tags { “Queue” = “Transparent” } RenderType 对着色器进行分类,例如这是一个不透明的着色器,或是一个透明的着色器.这可以用于着色器替换功能(啥玩意) Tags { “RenderType” = “Opaque” } DisableBatching 一些SubShader在使用Unity批处理功能时会出现问题,例如使用了模型空间下的坐标进行顶点动画(详见第11.3节).这时可以通过该标签来指明是否对该SubShader使用批处理. Tags { “DisableBatching” = “True” } ForceNoShadowCasting 控制使用该SubShader的物体是否会投射阴影(详见8.4)节 Tags { “ForceNoShadowCasting” = “True” } IgnoreProjector 如果该标签设置为True,那么使用该SubShader的物体不会受到projector的影响.通常用于半透明物体. Tags { “IgnoreProjector” = “True” } CanUseSpriteAtlas 当该SubShader是用于精灵时,将该标签设为False Tags { “CanUseSpriteAtlas” = “False” } PreviewType 指名材质面板将如何预览该材质.默认情况下,材质将显示为一个球形.我们可以通过将该标签的值设为”Plane” “SkyBox”来改变预览类型. Tags { “PreviewType” = “Plane” } Pass语义块Pass语义块包含的语义如下 12345Pass &#123; [Name] [Tags] // Other Code&#125; 首先,我们可以在Pass中定义该Pass的名称,例如 1Name &quot;MyPassName&quot; 通过这个名称,我们可以使用Shader的UsePass命令来直接使用其他UnityShader中的Pass.例如: 1UsePass &quot;MyShader/MYPASSNAME&quot; 这样可以提高代码的复用性.需要注意的是,由于Unity内部会把所有Pass的名字转换成大写字母的表示,因此在使用UsePass命令时必须使用大写的名字. Pass同样可以设置标签,但它的标签不同于SubShader标签.这些标签也是告诉渲染引擎我们希望怎么来渲染该物体. 标签类型 说明 例子 LightMode 定义该Pass在Unity的渲染管线中的角色 Tags { “LightMode” = “ForwardBase” } RequiresOptions 用于指定当满足某些条件时才渲染该Pass,它的值是一个由空格分隔的字符串.目前,Unity支持的选项有: SoftVegetation. 在后面的版本中,可能会增加更多的选项. Tags{ “RequireOption” = “SoftVegetation” } 除了上面的普通Pass定义外,Unity Shader还支持一些特殊的Pass, 以便进行代码复用或实现更复杂的效果. UsePass如之前所说,可以引入其他Unity Shader中的Pass. GrabPass负责抓取屏幕并将结果存储在一张纹理中,以用于后续的Pass处理(详见10.2.2节) FallBack1234FallBack &quot;name&quot;FallBack OffFallBack &quot;VertexLit&quot; 事实上,FallBack还会影响阴影的投射.在渲染阴影纹理时,Unity会在每个UnityShader中寻找一个阴影投射的Pass.通常情况下,我们不用自己专门实现一个阴影投射的Pass,这是因为FallBack使用内置Shader中包含了这样一个通用Pass. 因此,为每个UnityShader设置正确的FallBack是非常重要的. UnityShader的形式尽管UnityShader可以做的事情非常多(如设置渲染状态等),但其最重要的任务还是指定各种着色器所需的代码.这些着色器代码可以写在Shader语义块中(表面着色器的做法),也可以写在Pass语义块中(顶点/片元着色器和固定函数着色器的做法). 表面着色器Surface Shader是Unity自己创造的一种着色器代码类型.它需要的代码量很少,Unity在背后做了很多工作,单渲染代价比较大.当给Unity提供一个表面着色器的时候,它在背后仍旧会将它转换成对应飞顶点/片元着色器. 它存在的价值在于,Unity为我们处理了很多光照细节,使得我们不需要再操心这些烦人的事情.一个非常简单的表面着色器示例代码: 12345678910111213141516Shader &quot;Custom/sur&quot;&#123; SubShader&#123; Tags &#123;&quot;RenderType&quot; = &quot;Opaque&quot;&#125; CGPROGRAM #pragma surface surf Lambert struct Input &#123; float4 color:COLOR; &#125;; void surf(Input In, inout SurfaceOutput o) &#123; o.Albedo = 1; &#125; ENDCG &#125; Fallback &quot;Diffuse&quot;&#125; 上述程序可以看出,表面着色器被定义在SubShader语义块(而非Pass语义块)中的CGPROGRAM和ENDCG之间.原因是,表面着色器不需要关心开发者使用多少个Pass,每个Pass如何渲染等问题,Unity会在背后去帮我们做好这些事情.我们要做的只是告诉它,”用这些纹理去填充颜色,用这个法线纹理去填充法线,使用Lambert光照模型” CGPROGRAM和ENDCG之间的代码是使用Cg/HLSL编写的,也就是说,我们需要把Cg/HLSL语言嵌套在ShaderLab中.值得注意的是,这里的Cg/HLSL是Unity经过封装后提供的,它的标准语法和标准的Cg/HLSL几乎一样,但还是有细微不同.例如有些原生的函数和用法Unity并没有提供支持. 顶点/片元着色器Vertex/Fragment Shader更加复杂,但灵活性更高. 123456789101112131415161718192021Shader &quot;Custom/vertexfragment&quot;&#123; SubShader&#123; Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag float4 vert(float4 v : position) : SV_POSITION&#123; return mul(UNITY_MATRIX_MVP, v); &#125; float4 frag() : SV_Target&#123; return fixed4(1.0,0.0,0.0,1.0); &#125; ENDCG &#125; &#125;&#125; 和表面着色器类似,顶点/片元着色器的代码也需要定义在CGPROGRAM和ENDCG中间.但不同的是,顶点/片元着色器是写在Pass语义块中的,而非SubShader语义块内.原因是我们需要自己定义每个Pass需要使用的Shader代码.虽然我们可能需要编写更多的代码,但带来的好处是灵活性很高.更重要的是,我们可以控制渲染的实现细节. 固定函数着色器Fixed Function Shader弃子,现在不怎么用的着色器上面两种着色器都是用了可编程管线.而对于一些较旧的设备,它们不支持可编程管线着色器,因此,我们就需要使用固定函数着色器.这些着色器往往只能完成一些非常简单的效果]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
        <tag>《shader入门精要》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《shader入门精要》笔记-第二章-渲染流水线]]></title>
    <url>%2Fshader-r-lsx%2F</url>
    <content type="text"><![CDATA[看完数学部分后再来写的 CPU流水线将数据加载到显存中 把渲染所需所有数据从硬盘加载到系统内存中 网格和纹理等数据又被加载到显存中 设置渲染状态这些状态定义了场景中的网格是怎么被渲染的例如,使用哪个顶点着色器/片元着色器,光源属性,材质等.如果我们没有设置渲染状态,那么所有网格都将使用同一种渲染状态 调用DrawCallDraw Call是一个命令,发起方是CPU,接收方是GPU.这个命令仅仅会指向一个需要被渲染的图元的列表,而不再包含任何材质信息–因为已经在上个阶段完成了. 当给定一个Draw Call时,GPU会根据渲染状态(材质,纹理,着色器等)和所有输入的顶点数据来进行计算,最终输出到屏幕 GPU流水线顶点数据 -&gt; 顶点着色器 -&gt; 曲面细分着色器 -&gt; 几何着色器 -&gt; 裁剪 -&gt; 屏幕映射 -&gt; 三角形设置 -&gt; 三角形遍历 -&gt; 片元着色器 -&gt; 逐片元操作 -&gt; 屏幕图像 顶点着色器顶点无法销毁或创建顶点,也不可以获得顶点之间的联系.例如,我们无法判断两个顶点是否处于同一个网格.正是因为这样的相互独立性,GPU可以利用本身的特性并行化处理每一个顶点,这意味着这一阶段的处理速度会更快.顶点着色器需要完成的主要工作有:坐标变换和逐顶点光照当然除了这两个主要任务外,顶点着色器还可以输出后续阶段所需的数据. 坐标变换把顶点坐标从模型空间变换到齐次剪裁空间 剪裁摄像机的视野范围内很有可能不会覆盖场景中的所有物体.不在摄像机视野范围内的物体不需要处理.剪裁就是为了完成这个目标而被提出来的. 我们无法通过编程来控制剪裁的过程,而是硬件上的固定操作,但我们可以自定义一个剪裁操作来对这一步进行配置. 屏幕映射屏幕映射的任务是把每个图元的x,y坐标转换到屏幕坐标系. 三角形设置从这一步开始进入光栅化阶段.从上一个阶段输出的信息是屏幕坐标系下的顶点位置以及它们的额外信息,如深度值(z坐标),法线方向,视角方向等.光栅化阶段有两个最重要的目标:计算每个图元覆盖了哪些像素,以及为这些像素计算它们的颜色. 三角形设置阶段会计算光栅化一个三角网格所需的信息.具体来说,上个阶段输出的都是三角网格顶点.但如果要得到整个三角网格对像素覆盖的情况,我们就必须计算每条边上的像素坐标.为了能够计算边界像素的坐标信息,我们就需要得到三角形边界的表达方式.这样一个计算三角形网格表示数据的过程就叫做三角形设置.它的输出是为了给下一步做准备. 三角形遍历三角形遍历阶段会检查每个像素是否被一个三角网格所覆盖.如果被覆盖的话,就生成一个片元而这个找到哪些像素被三角网格覆盖的过程就是三角形遍历,这个阶段也被称为扫描变换. 三角形遍历会根据上一个阶段的计算结果来判断一个三角网格覆盖了哪些像素,并使用三角网格三个顶点的顶点信息对整个覆盖区域的像素进行插值. 这一步的输出就是得到一个片元序列.需要注意的是,一个片元并不是真正意义上的像素,而是包含了很多状态的集合,这些状态用于计算每个像素的最终颜色这些状态包括了(但不限于)它的屏幕坐标,深度信息,以及其他从几何阶段输出的顶点信息,如法线,纹理坐标等. 片元着色器前面的光栅化操作并不会影响屏幕上每个像素的颜色值,而是会产生一系列的数据信息,来描述一个三角网格是怎样覆盖每个像素的.而片元就是负责存储这样一系列数据.真正会对像素产生影响的是下一个阶段–逐片元操作 片元着色器的输入是上一个阶段对顶点信息插值得到的结果.更具体来说,是根据那些从顶点着色器中输出的数据差值得到的.它的输出是一个或多个颜色值. 这一阶段可以完成很多重要的渲染技术,其中最重要的技术之一是纹理采样.为了在片元着色器中进行纹理采样,我们通常会在顶点着色器阶段输出每个顶点对应的纹理坐标然后经过光栅化阶段对三角形网格的三个顶点对应的纹理坐标进行插值后,就可以得到其覆盖片元的纹理坐标了. 片元着色器的局限在于,它仅可影响单个片元.也就是说,在执行片元着色器时,它不可以将自己的任何结果发送给它的邻居们.有一个情况例外,就是片元着色器可以访问到导数信息(扩展阅读)(smjb) 逐片元操作也被称为输出合并阶段这一阶段的几个重要任务: 决定每个片元的可见性. 这涉及很多测试工作,如深度测试,模板测试等 合并 如果一个片元通过了所以测试,就需要把这个片元的颜色值和已经存储在颜色缓冲区中的颜色进行混合 逐片元操作是高度可配置的.即我们可以设置每一步的操作细节.]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
        <tag>《shader入门精要》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bili-api]]></title>
    <url>%2Fbili-api%2F</url>
    <content type="text"><![CDATA[url 描述 https://api.bilibili.com/x/relation/stat?vmid={uid} up粉丝数 https://api.bilibili.com/x/space/upstat?mid={uid} 观看量 https://api.bilibili.com/x/space/navnum?mid={uid} 投稿数量 https://api.bilibili.com/x/space/acc/info?mid={uid} 基本信息 https://api.bilibili.com/x/space/masterpiece?vmid={uid} 代表作]]></content>
  </entry>
  <entry>
    <title><![CDATA[《shader入门精要》笔记-第四章-数学基础]]></title>
    <url>%2Fshader-r-math%2F</url>
    <content type="text"><![CDATA[《shader入门精要》免费的第四章pdf 点和矢量点积(内积)和叉积(外积)内积Shader代码中使用dot(a,b)来进行矢量的点积运算. 1a·b = (a x , a y , a z ) ·(b x , b y , b z ) = a x b x + a y b y + a z b z 满足交换律和结合律.使用: 投影 单位矢量a,和一个长度不限制的矢量b,dot(a,b)得到b在a方向上带有符号的投影 外积外积的结果时矢量,并非标量. 1a X b = (a x , a y , a z ) X (b x , b y , b z ) = (a y b z - a z b y , a z b x - a x b z , a x b y - a y b x ) 例如:(1, 2, 3) X (−2, −1, 4) = ((2)(4) − (3)(−1), (3)(−2) − (1)(4), (1)(−1) − (2)(−2))= (8 − (−3), (−6) − 4, (−1) − (−4)) = (11, −10, 3)外积不满足交换律,即a X b不等于b X a.然而外积满足反交换律,即a X b = -(b X a)外积不满足结合律. 矩阵(matrix)矩阵运算矩阵乘法 矩阵乘法不满足交换律 AB不等于BA 矩阵乘法满足结合律 (AB)C = A(BC) shader中主要使用4x4矩阵来运算. 特殊矩阵方块矩阵(方阵)行和列数目相等的矩阵.三维渲染里,用的最多的是3x3和4x4的方阵 单位矩阵用In来表示.比如I3是3x3的单位矩阵. 转置矩阵transposed matrix转置矩阵实际是对原矩阵的一种运算,即转置运算.给定一个rXc的矩阵M,他的转置可以表示为MT(T为上标)(辣鸡MD).数学公式是:例如: 转置矩阵性质: 转置矩阵的转置等于原矩阵(废话) 矩阵的串接转置等于反向串接各个矩阵的转置 即: 逆矩阵给定一个矩阵M,用M-1(-1为上标)表示M的逆矩阵.MM-1为单位矩阵 矩阵可逆的条件: 矩阵为方块矩阵 矩阵的行列式不为零 虽说在学数学…但是也是shader开发里的数学…还是不去回忆具体怎么求逆矩阵了,交给程序去做=v= 逆矩阵的性质 逆矩阵的逆矩阵等于原矩阵 单位矩阵的逆矩阵是其本身 转置矩阵的逆矩阵等于逆矩阵的转置 即: 矩阵串接相乘后的逆矩阵等于反向串接各个矩阵的逆矩阵 即: 正交矩阵蒸饺正交是矩阵的一种属性.如果一个方阵M和它的转置矩阵的乘积是单位矩阵的话,我们说这个矩阵是正交的即: 行矩阵or列矩阵?书上p64这里不说过程了.结论是,unity中习惯把矢量转换成列矩阵,并放在矩阵的右侧进行计算. 矩阵的几何意义: 变换变换的类型线性变换可以保留矢量加和标量乘的变换.用数学公式表达即是:上面的式子很抽象.缩放就是一种线性变换.如f(x) = 2x,可以表示一个大小为2的统一缩放.旋转也是一种线性变换 对于线性变换来说,仅仅使用3X3矩阵可以表示三维坐标下的所有线性变换.线性变换除了包括旋转和缩放外,还包括错切,镜像,正交投影等. 仿射变换仅有线性变换是不够的,要考虑平移交换.如,f(x) = x + (1,0,0)这个变换就不是一个线性变换.三维坐标下,我们不能用一个3x3的矩阵来表示一个平移变换.这样,就有了仿射变换.仿射变换是合并了线性变换和平移变换的变换类型.三维空间下的仿射变换可以用一个4x4的矩阵来表示.为此,我们需要把矢量扩展到四维空间下,这就是齐 次 坐 标 空 间(homogeneous space).不知道是什么鸡儿玩意单好像以后有用的表 齐次坐标因为3X3矩阵不能表示平移,所以我们用4x4矩阵.为此,我们还需要把原来的三维矢量转换成四维矢量,也就是齐次坐标(homogeneous coordinate).对于一个点,从三维坐标转换为齐次坐标是将其w分量设为1,而对于方向矢量而言,需要把其w分量设为0.这样的设置会导致,用一个4x4矩阵对一个点进行变换的时候,平移,缩放,旋转都会被施加于该点.但是如果用于变换一个方向矢量,平移的效果就会被忽略. 分解基础变换矩阵我们可以把一个基础变换矩阵分解成4个组成部分.其中,左上角的M是一个用于旋转和缩放的三维矩阵.t表示平移.最后一行是固定的[0 0 0 1] 平移矩阵M为单位矩阵时,整个4x4矩阵只代表平移.平移矩阵的逆矩阵就是反向平移的矩阵. 缩放矩阵如果缩放系数kx = ky = kz,我们把这样的缩放称为统一缩放否则称为非统一缩放.直观上看,统一缩放就是等比缩放模型,而非统一缩放会拉伸或挤压模型.统一缩放不会改变角度和比例信息,非统一缩放会改变模型相关的角度和比例.在进行法线变换时,如果存在非统一缩放,直接用于变换顶点的变换矩阵的话,就会得到错误的结果.(正确的方法见4.7节(还没发货哦草)) 旋转矩阵按x轴旋转: 按y轴旋转 按z轴旋转 复合变换我们可以把平移,旋转,缩放结合起来,组成一个复杂的变换过程.例如,可以对一个模型先进行大小为(2, 2, 2)的缩放,再绕y轴旋转30度,最后向z轴平移4个单位.复合矩阵可以通过矩阵的串联来实现.如:需要注意的是,因为矩阵的乘法不满足交换律,变换的结果是依赖于变换顺序的.绝大多数情况下,我们约定变换的顺序是,先缩放,再旋转,最后平移. 坐标空间模型空间也称对象空间或局部空间. 世界空间最外层的坐标空间 观察空间也称为摄像机空间Unity中观察空间的+x轴指右方,+y轴指向上方,+z轴指向摄像机的后方—-Unity在模型空间和世界空间选用的是左手坐标系,而观察者空间选用右手坐标系. 观察空间和屏幕空间是不同的.观察空间是一个三维空间,而屏幕空间是一个二维空间.从观察空间到屏幕空间需要一个投影(projection)转换. 顶点变换的第二步,就是将顶点坐标从世界空间变换到观察空间.这个变换通常叫做观察变换. 剪裁空间顶点接下来要从观察者空间转换到剪裁空间(clip space,也被称为齐次裁剪空间)中,这个用于变换的举证叫做裁剪矩阵(clip matrix),也被称为投影矩阵(projection matrix).剪裁空间的目标是能够方便地对渲染图元进行裁剪.完全位于这块空间内部的图元将会被保留,完全处于这块空间外部的图元将会被剔除,而与这块空间边界相交的图元就会被裁剪.这块空间是由视锥体(view frustum)决定的. 视锥体指的是空间中的一块区域,这块区域决定了摄像机可以看到的空间.视锥体由留个平面包围而成,这些平面被称为裁剪平面(clip planes).视锥体有两种类型,这涉及两种投影类型—-一种是正交投影(orthographic projection),一种是透视投影(perspective projection)透视投影会有远小近大. 在视锥体的6块裁剪平面中,有两块裁剪平面比较特殊,分别是近剪裁平面(near clip plane)和远剪裁平面(far clip plane).它们决定了摄像机可以看到的深度范围.我们通过一种通用,简洁的方式进行剪裁工作,这种方式是通过一个投影矩阵把顶点转换到一个剪裁空间中.投影矩阵有两个目的: 首先是为投影做准备.这是个迷惑点,虽然投影矩阵包含了投影二字,但是它并没有进行真正的投影工作,而是在为投影做准备.真正的投影发生在后面的齐次排除法(homogeneous division)过程中.而经过投影矩阵变换后,顶点的w分量将会具有特殊意义. 其次是对x,y,z分量进行缩放.经过投影矩阵的缩放以后,我们可以直接使用w分量作为一个范围值,如x,y,z都在这个范围内,就说明该顶点位于剪裁空间内. 1.透视投影视锥体的六个剪裁平面是由Camera组件中的参数和Game视图的横纵比共同决定的.如图所示,我们可以通过Camera组件的Field of View(简称FOV)属性来改变视锥体竖直张开的角度,而Cliping Planes中的Near和Far属性可以控制视锥体的近剪裁平面和远剪裁平面距离摄像机的远近.这样,我们可以求出视锥体近剪裁平面和远剪裁平面的高度.一个摄像机的横纵比由Game视图的横纵比和Viewport Rect中的W和H属性共同决定.假设,当前摄像机的横纵比是Aspect:现在,我们可以根据已知的Near,Far,FOV和Aspect的值来确定透视投影的投影矩阵.推导见本章的扩展阅读部分一个顶点和上面的投影矩阵相乘后,可以由观察者空间变换到剪裁空间.从结果可以看出来,投影矩阵的本质是对x,y,z分量做了不同的缩放(z分量还做了一个平移).缩放的目的是为了方便裁剪.可以注意到,此时顶点的w分量不再是1,而是原先z分量的取反.现在,我们就可以按如下不等式判断一个变换后的顶点是否位于视锥体内.如果一个顶点在视锥体内,那么它变换后的坐标必须满足: -w &lt;= x &lt;= w -w &lt;= y &lt;= w -w &lt;= z &lt;= w 任何不满足上述条件的图元都需要被剔除或者裁剪.通过此图还可以注意到,剪裁矩阵会改变空间的旋向性:空间从右手坐标系变换到了左手坐标系. 2. 正交投影和透视投影类似,在unity中,正交投影的六个人裁剪平面是由Camera组件中的参数和Game视图的横纵比共同决定的.由图看出,我们可以通过Camera组件的Size属性来改变视锥体竖直方向上的高度的一半,而Clipping Planes中的Near和Far参数可以控制视锥体的近剪裁平面和远剪裁平面距离摄像机的远近.这样,我们可以求出视锥体近剪裁平面和远剪裁平面的高度.即:同样,我们可以通过摄像机的横纵比得到横向信息.假设当前摄像机的横纵比为Aspect: 现在我们根据已知的Near,Far,Size和Aspect的值来确定正交投影的裁剪矩阵.如下:推导见本章的扩展阅读一个顶点和上述投影矩阵相乘后的结果如下:注意到,和透视投影不同,使用正交投影的投影矩阵对顶点变换后,其分量w依然为1.本质是因为投影矩阵最后一行的不同,透视投影的投影矩阵的最后一行是[0 0 -1 0],而正交投影的投影矩阵最后一行是[0 0 0 1].这样选择是为了为齐次除法做准备(具体在下面讲到) 判断一个变换后的顶点是否位于视锥体内使用的不等式和透视投影的一样. 同样,裁剪矩阵改变了空间的旋向性.可以注意到,经过正交投影变换后的顶点实际已经位于一个立方体内了. 屏幕空间经过了投影矩阵的变换后,我们可以进行剪裁工作.当完成了所有的剪裁工作后,就需要进行真正的投影了.也就是说,我们需要把视锥体投影到屏幕空间(screen space)中.经过这一步变换,我们会得到真正的像素位置,二非虚拟的三维坐标. 屏幕空间是一个二维空间,因此我们需要把顶点从剪裁空间投影到屏幕空间,来生成对应的2D坐标.这个过程分为两个步骤 首先,我们要进行标准齐次除法(homogeneous division),也被称为透视除法(perspective division).虽然这个步骤听起来陌生,但它实际上非常简单,就是用齐次坐标系的w分量去除以x,y,z分量.在OpenGL中,我们把这一步得到的坐标叫做归一化的设备坐标(Normalized Device Coordinate, NDC).经过这一步,我们可以把坐标从齐次剪裁坐标空间转换到NDC中.经过透视投影变换后的剪裁空间,经过齐次除法后会变换到一个立方体内. 对于透视投影 对于正交投影 经过齐次除法后,透视投影的剪裁空间会变换到一个立方体 对于正交投影来说,它的剪裁空间实际已经是一个立方体了,而且由于经过正交投影矩阵变换后的顶点的w分量是1,因此齐次除法并不会对顶点的x,y,z坐标产生影响 经过齐次除法后,透视投影和正交投影的视锥体都变换到一个相同的立方体内.现在,我们可以根据变换后的x,y坐标来映射输出窗口的对应像素坐标.这个映射的过程是一个缩放的过程.齐次除法和屏幕映射的过程可以用下面的公式总结:上面式子对x和y分量进行了处理,而z分量会被用于深度缓冲.一个传统的方式是把clip z / clip w的值直接存进深度缓冲中,但这不是必须的.通常驱动的生产商会根据硬件来选择最好的存储格式.此时clip w也并未抛弃,虽然它已经完成了它的主要工作–在齐次除法中作为分母来得到NDC,但它仍然会在后续的一些工作中起到重要作用.例如进行透视矫正差值(草,这又是什么玩意) 在Unity中,从剪裁空间到屏幕空间的转换是底层帮我们完成的.我们的顶点着色器只需要把顶点转换到剪裁空间即可. 总结以上就是一个顶点如何从模型空间最终转换到屏幕空间的全过程. 顶点着色器的最基本的任务是把顶点坐标从模型空间转换到剪裁空间中.这对应了上图中的前三个顶点变换过程.而在片元着色器中,我们通常也可以得到该片元在屏幕空间的像素信息.我们会在4.9.3节中看到如何得到这些像素位置. 在Unity中,坐标系的旋向性也随着发生了改变.只有在观察空间使用了右手坐标系. 需要注意的是,这里仅仅给出的是一些最重要的坐标空间.还有一些空间在实际开发中也会遇到,如切线空间(tangent space).切线空间通常用于法线映射. 法线变换法线(normal),也被称为法矢量(normal vector).在游戏中,模型的一个顶点往往会携带额外的信息,而顶点法线就是其中的一种信息.当我们变换一个模型的时候,不仅要变换它的顶点,还需要变换它的法线,以便在后续的处理(如片元着色器)中计算光照等.玛德这块数学公式太多了md不要表达,反正本来的这块内容就没多少去书上看吧. Unity Shader的内置变量(数学篇)变换矩阵这里是Unity5.2版本提供的所有内置变换矩阵.所有矩阵都是float4x4的. 变量名 描述 _Object2World 当前的模型矩阵,用于将顶点/方向矢量从模型空间变换到世界空间 _World2Object _Object2World的逆矩阵.用于将顶点/方向矢量从世界空间变换到模型空间 UNITY_MATRIX_V 当前的观察矩阵,用于将顶点/方向矢量从世界空间变换到观察空间 UNITY_MATRIX_P 当前的投影矩阵,用于将顶点/方向矢量从观察空间变换到剪裁空间 UNITY_MATRIX_MV 当前的模型矩阵·观察矩阵,用于将顶点/方向矢量从模型空间变换到观察空间 UNITY_MATRIX_VP 当前的观察矩阵·投影矩阵,用于将顶点/方向矢量从世界空间转换到剪裁空间 UNITY_MATRIX_MVP 当前的模型矩阵·观察矩阵·投影矩阵,用于将顶点/方向矢量从模型空间变换到剪裁空间 UNITY_MATRIX_T_MV UNITY_MATRIX_MV的转置矩阵 UNITY_MATRIX_IT_MV UNITY_MATRIX_MV的逆转置矩阵,用于将法线从模型空间变换到世界观察空间,也可用于得到UNITY_MATRIX_MV的逆矩阵 UNITY_MATRIX_T_MV这个矩阵比较特殊.对于正交矩阵来说,它的逆矩阵就是转置矩阵.因此,如果UNITY_MATRIX_MV是一个正交矩阵的话,那么UNITY_MATRIX_T_MV就是它的逆矩阵,也就是说,我们可以使用UNITY_MATRIX_T_MV将顶点/方向矢量从观察空间变换到模型空间 UNITY_MATRIX_IT_MV这个矩阵也要特殊说明一下.法线的变换需要使用原变换矩阵的逆转矩阵,因此UNITY_MATRIX_IT_MV可以把发现从模型空间变换到观察者空间.而且,只需要对它进行转置,就可以得到UNITY_MATRIX_MV的逆矩阵因此,为了把顶点或法线矢量从观察者空间变换到模型空间,我们可以使用以下代码: 12345// 方法一: 使用transpose函数对UNITY_MATRIX_IT_MV进行转置,得到UNITY_MATRIX_MV的逆矩阵,然后进行列矩阵乘法,把观察空间中的点或方向矢量变换到模型空间中 float4 modelPos = mul(transpose(UNITY_MATRIX_IT_MV), viewPos);// 方法二: 不直接使用转置函数transpose, 而是交换mul参数的位置,使用行矩阵乘法. 本质是一样的.float4 modelPos = mul(viewPos, UNITY_MATRIX_IT_MV); 摄像机和屏幕参数Unity提供了一些内置变量来让我们访问当前正在渲染的摄像机的参数信息.这些参数对应了摄像机上的Camera组件中的属性值. 变量名 类型 描述 _WorldSpaceCameraPos float3 该摄像机在世界空间中的位置 _ProjectionParams float4 x = 1.0(或-1.0, 如果正在使用一个翻转的投影矩阵进行渲染), y = Near, z = Far, w = 1.0 + 1.0/Far _ScreenParams float4 x = wodth, y = height, z = 1.0 + 1.0/width, w = 1.0 + 1.0/height _ZBufferParams float4 x = 1 - Far/Near, y = Far/Near, z = x/Far, w = y/Far, 该变量用于线性化Z缓存中的深度值(可参考13.1节) unity_OrthoParams float4 x = width, y = height,z没有定义,w = 1.0(该摄像机是正交摄像机),或w = 0.0(该摄像机是透视摄像机) unity_CameraProjectio float4x4 该摄像机的投影矩阵 unity_CameraInvProjection float4x4 该摄像机的投影矩阵的逆矩阵 unity_CameraWorldClipPlanes[6] float4 该摄像机的6个裁剪平面在世界空间下是等式.按如下顺序:左,右,下,上,近,远裁剪平面]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
        <tag>《shader入门精要》</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10-Insider-Preview]]></title>
    <url>%2Fwin10-Insider-Preview%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[博客上放上live2d]]></title>
    <url>%2Fblog-live2d%2F</url>
    <content type="text"><![CDATA[很久前就看到在网站上挂个live2d,也有想法了,然而从昨晚才开始折腾.想在博客上放个舰b的live2d,结果试了好久,版本二到版本三,从民间到官方的web sdk都试了,就没有支持舰b的live2d的T_T最后妥协了下,选了有前车之鉴的药水制作师的live2d.最喜欢之前拿红宝石买来的樱花校服装了. 阿黑颜pio 参考: 猫与向日葵的博客 Cubism WebGL SDK]]></content>
      <tags>
        <tag>live2d</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shader学习]]></title>
    <url>%2Fshader-learning%2F</url>
    <content type="text"><![CDATA[资料 Shader编程教程-蛮牛 Unity User Manual 第一课 图形硬件简史与可编程管线课时总结 2003年开始正式进入可编程GPU阶段 GPU的并行处理能力强于CPU 目前GPU无法代替CPU 第二课 shader和渲染管线 GPU前段模块-&gt;图源装配:过去只有集成在硬件当中的顶点着色器,现在可编程 光栅化:把计算机显卡当中运算的数据进行一个细分用于适配屏幕上具体的每一个像素的显示 像素运算:光栅化不等同于像素运算.像素运算最终反映的是颜色,光栅化过后得到的结果是帧缓存.这个过程中可以加入片段着色器. Vertex Processor顶点处理程序,运算的结果将会交给像素处理器 Frame Buffer帧缓冲中容纳了是计算机依次显示所要使用的数据,但不只是屏幕上用语显示的颜色的信息,可能还有其他的附加信息.比如深度值 Transform, TexGen, Lighting Transform 模型的空间变换(针对顶点的空间几何变换) Texture Generator 纹理坐标的生成,主要用于在顶点当中取得纹理坐标,纹理坐标转化为uv取值的范围 Lighting 光照 Vertex Shader 改变上个模块的光照,变换,纹理生成等 Culling Depth Test Culling 裁剪.物体在镜头面前展示,背对摄像头的面看不到,可能就会被裁剪,不处理看不到的面的顶点数据. Depth Test 深度测试.范围超过摄像头最近或最远的渲染范围之后,也会被剔除 Texturing Fog 纹理采样.进入光栅化阶段.从纹理当中找到纹理中对应的一个点 Fragmen Shader 远处的物体可能需要雾化处理.处于片段shader的可编程范围 Alpha Test 绘制半透明或全透明物体 Blending 混合最终的图像 可编程能力是两个部分,一部分是变换和光照,使用顶点shader编写顶点着色器如何采样,计算颜色以及雾化处理等等,这部分放到片段着色器 unity当中,优化主要部分是减少游戏调用gpu渲染的调度次数.CPU搜集数据,产生GPU调度数据.这个过程是昂贵的. shader和材质,贴图的关系shader实际上是一小段程序.负责将输入的顶点数据以指定的方式和输入的贴图或者颜色组合起来然后输出.绘图单元可以依据这个输出将图像绘制到屏幕上.输入的贴图或者颜色等,加上对应的shader,以及对shader]d特定的参数设置,将这些内容(shader及输入参数)打包存储在一起.得到的就是一个Material(材质).之后我们便可以将材质赋予三维物体来渲染(输出)了. 材质好比引擎最终的商品,shader是生产这种商品的加工方法,而贴图是原材料. 课时总结 Shader是图形可编程方案的程序片段 渲染管线是一种计算机从数据到最终图形成像的形象描述 材质是商品,shader是方法,贴图是材料 第三课 shader的三大主流高级编程语言 HLSL 基于DirectX的High Level Shading Language GLSL 基于OpenGL的OpenGL Shading Language CG NVIDIA公司的C for Graphic 第四课 Unity Shader的组织形式 surface shader unity推荐和鼓励的shader.图形管线能够用于识别的,就是vertex and fragment shader.surface shader是对vertex and fragment shader的一种包装.unity最终会把surface shader编译成能被硬件识别和调用的vertex and fragment shader vertex and fragment shader fixed function shaders 固定管线的shader.Shaderlab 语法基本结构 12345678910111213141516Shader &quot;MyShader&quot; &#123; Properties &#123; _MyTexture (&quot;My Texture&quot;, 2D) = &quot;white&quot; &#123; &#125; // place other properties here, such as colors or vectors. &#125; SubShader &#123; // place the shader code here for your: // - surface shader, // - vertex and program shader, or // - fixed function shader &#125; SubShader &#123; // a simpler version of the subshader above goes here. // this version is for supporting older graphics cards. &#125;&#125; unity自带shader Unlit 不发光 VertexLit 顶点光照 Diffuse 漫反射.不仅仅在顶点上进行光照计算,在片段上进行光照计算 Normal Mapped 法线贴图.用的比较多.通过一张贴图进行采样.贴图是关于法向量存储的贴图.把这张图采样出的数据作为法向量再进行光照计算.主要目的是当几何模型面片数量,顶点数量不太多,为表达丰富的细节. Specular 高光.玻璃等 Normal Mapped Specular 高光法线贴图.较昂贵 Parallax Normal mapped 视差法线贴图 Parallax Normal mapped Specular 高光视差法线贴图 Fixed function shader固定功能的shader.功能有限但是性能很好 Surface ShaderSurface Shader无需编写pass通道]]></content>
      <categories>
        <category>shader</category>
      </categories>
      <tags>
        <tag>unity</tag>
        <tag>shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[夏目友人帐观影]]></title>
    <url>%2Fnazume-film%2F</url>
    <content type="text"><![CDATA[听说到容莉枝不管好事还是坏事都要去那个祠堂参拜的时候,就心想着那是个树洞,结果还真是个真实树洞233 前半那个笹田演讲的时候放的BGM就是那首熟悉的ふるさとの匂い,直接掉泪 容莉枝阿姨在儿子死后的八年间没有很痛苦是很好的,穗之影做得好.真正可怜的是穗之影啊草. 看之前的剧情以为名取对夏目图谋不轨来着,这次看名取的心理活动,还是个好人.]]></content>
      <categories>
        <category>动漫</category>
      </categories>
      <tags>
        <tag>动漫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习unity]]></title>
    <url>%2Funity-learning%2F</url>
    <content type="text"><![CDATA[unity官方教程https://unity3d.com/cn/learn/tutorials现在在看一个beagining教程roll a ball 起步material初探新建material,选择颜色后,将material拖到gameObject上,gameObject就会变成对应的颜色 Update方法 Update方法在渲染每帧前被调用 FixedUpdate方法只有在执行有关物理计算之前才被调用 LateUpdate方法在所有Update方法执行完执行完之后执行 静态和动态GameObject静态碰撞体unity会计算场景内所有静态碰撞体的体积,并将信息保存在缓存内.因为静态碰撞体不需要移动,可以避免每帧重新计算这些信息,所以这是对的每当静态碰撞体移动 旋转或缩放时,unity会重新计算这些静态碰撞体,然后更新静态碰撞体的缓存数据 动态碰撞体重新计算缓存会耗费系统资源,但我们可以随意移动移动,旋转或缩放动态碰撞体,而且unity不会缓存他们的数据.unity会预测动态碰撞体的移动,所以在移动碰撞体之前,需要告诉unity它们是动态的.可以使用刚体组件来实现这种效果. 任何带有碰撞体和刚体组件的GameObject都会被认为是动态的.任何带有碰撞体却没有刚体组件的GameObject则被视为是静态的.刚体选中”Is Kinematic”可以将刚体变成仅受脚本控制的刚体.kinematic刚体不受无力作用力的影响,但可以播放动画或通过Transform组件移动 几何图元绘制顺序Sorting LayerSorting Layer序号越大的层越后绘制,因而会覆盖掉前面序号小的层上的几何图元表示指定层在Tags and Layers视图Sorting Layers中的顺序各层的绘制顺序是Default -&gt; Background -&gt; Character -&gt; Foreground -&gt; UI Order in layer在同一层调整几何图元的绘制深度.同样是序号大的覆盖序号小的 spirit Render组件中SortingLayer属性控制的是不同层之间的绘制顺序,而Order in Layer控制的是同层中物体的绘制顺序 spine可算知道瓜游的小人都是什么了一开始下的spine3.7,然后于是又下了3.6.卸载旧版本插件好像是直接在project里把对应的删掉目力俾斯麦蛮好玩的 U!P!D!A!T!E!写unity程序跟平常写其他程序一个很不一样的思想就是unity的每帧都会执行的update.平时写程序如果遇到时间相关的,就要考虑sleep,然后就要考虑阻塞,考虑协程或多线程.而unity不一样.利用unity的update机制可以很轻易的管理时间. Shader12345678910111213141516171819Shader "Unlit/Tutorial_Shader"&#123; // 属性块 Properties&#123; // 在属性块中，我们可以传递一些自定义数据。我们在这里声明的数据将被显示在Unity Editor面板中，在Editor中更改也会驱动脚本更改。 // 感觉类似于C#脚本里的public声明变量 &#125; SubShader&#123; // 每一个shader有一个或者多个subshaders,如果你的应用将被部署到多种平台（移动、PC、主机）,添加多个Subshader是非常有用的。例如：你可能想要写为PC/Desktop写一个高质量的Subshader,为移动端写一个低质量,但速度更快的Subshader. // 每个Subshader至少有一个pass语句块，它实际上是对象渲染的位置。一些特效要求有多个pass语句块，目前，我们仅仅专注于一个。 pass&#123; CGPROGRAM // 我们实际写的所有Shader代码都在CGPROGRAM和ENDCG中 ENDCG &#125; &#125;&#125; 蛋疼md写shader真蛋疼,啥时候需要分号啥时候不需要啊草草草]]></content>
      <categories>
        <category>unity</category>
      </categories>
      <tags>
        <tag>unity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试笔记]]></title>
    <url>%2Fnote-interview%2F</url>
    <content type="text"><![CDATA[位运算可以节约传输和储存的空间 unity，c#，lua，opengl，渲染]]></content>
  </entry>
  <entry>
    <title><![CDATA[加了几个音乐收藏夹]]></title>
    <url>%2FmusicFavorites%2F</url>
    <content type="text"><![CDATA[想着给把最喜欢,最常听的几首歌按风格分类,造了这么几个歌单 治愈 爱 静谧 朝气蓬勃 优美忧伤 对这些歌写点东西治愈urar很美好. 蝴蝶泉边同样很美好很温馨,更加了点回忆的感觉 Growing!就是让人撒娇的歌 爱Letter动画HandShaker的BGM中听到的.前面一段代表书信的常规内容,后面深深的感情喷涌而出.不像小情侣之间的爱,像是老夫老妻或者亲情的爱这封Letter不像情书而是像家书 LuvLetter情书.写情书和纠结要不要将情书送出去的过程,理解的是纠结着很痛苦然后没能送出去.中间有纠结的痛苦,也有想象的美好结局. 恋日推给我的,高潮部分很好听 愛唄当初看一个高木同学的AMV注意到的,很真情实感 小小恋歌同样是高木同学ed收录的当初觉得高桥李依版本的好听,比较甜美来着,后来还是觉得新垣结衣唱的好听,捎带沙哑点的声音很温柔很知性 さよならの夏啊 静谧Mountain stream高中时候学校就经常放的 陽だまり道とれんちょん悠哉日常大王的BGM ふるさとの匂い夏目友人帐的BGM 朝气蓬勃RYDEEN朝气蓬勃 优美忧伤おうちに帰りたいちいさな冒険者素晴的ed. Arrietty’s Song借东西的小人阿莉埃蒂的主题曲 春よ、来い看了一个潮学视频知道的…着实很好听 この感情は使命island的曲子 さよならの夏啊]]></content>
      <categories>
        <category>日常</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python多重继承init的问题]]></title>
    <url>%2Fpython-mult-inherit-init%2F</url>
    <content type="text"><![CDATA[继承的时候,init父类时,平时用ide写代码习惯了这样写,因为敲一个super再回车就有了这么一行1super(C, self).__init__() 12345678910111213141516class A: def __init__(self): self.a = "a" class B: def __init__(self): self.b = "b"class C(A,B): def __init__(self): super(C, self).__init__()if __name__ == '__main__': c = C() print(c.__dict__) # &gt;&gt;&gt; &#123;'a': 'a'&#125; 可以看出问题了,C类只init了A类,并没有init B类下面是我瞎摸出来的解决方法 1234567891011121314151617181920class A: def __init__(self): self.a = "a"class B: def __init__(self): self.b = "b"class C(A, B): def __init__(self): A.__init__(self) B.__init__(self)if __name__ == '__main__': c = C() print(c.__dict__) # &gt;&gt;&gt; &#123;'a': 'a', 'b': 'b'&#125;]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chrome插件踩坑]]></title>
    <url>%2Fchrome-crx%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[自动玩瓜游连连看的脚本]]></title>
    <url>%2Fazurlane-llk%2F</url>
    <content type="text"><![CDATA[做了个自动玩连连看的脚本.github : https://github.com/HHHHhgqcdxhg/azurlane-linkup 图片整理将原图整理成以下格式 原图: 整理出: 1234567[[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 16. 2. 4. 1. 3. 1. 2. 17. 3. 0.] [ 0. 8. 7. 14. 4. 10. 12. 18. 5. 5. 0.] [ 0. 6. 6. 9. 15. 7. 11. 8. 9. 10. 0.] [ 0. 11. 12. 13. 13. 14. 15. 16. 17. 18. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] #这个二维数组是抽象的连连看"地图",将原连连看相同的图片换成同样的数字,在在周围填充0表示通路 和12[[1, 6], [1, 4], [1, 7], [1, 2], [1, 9], [1, 5], [2, 4], [1, 3], [2, 9], [2, 8], [3, 2], [3, 1], [3, 5], [2, 2], [3, 7], [2, 1], [3, 8], [3, 3], [3, 9], [2, 5], [4, 1], [3, 6], [4, 2], [2, 6], [4, 4], [4, 3], [4, 5], [2, 3], [4, 6], [3, 4], [4, 7], [1, 1], [4, 8], [1, 8], [4, 9], [2, 7]]# 这个数组每一项表示一组坐标,并且第 2 * i 个元素代表的图片和第 2 * i + 1 个元素代表的图片相同 求解算法广度优先暴搜,搜索所有可以到达的图片块,判断目标是否在其中.代码在源码中的findLineFetch方法和pointSearch方法,注释还写的蛮详细的,这里不再解释. 实行点击:跟上次的翻牌游戏脚本差不多 结果7.80s视频: av450629917.80s留了视频,有一个7.27s的没录好…追求极致的话应该能跑进7秒内,说不定能跑进6秒内,我做不到一定是因为我太菜了 时间浪费 截图耗时 因为开局前截图会有数字遮挡,所以等数字消完,再进行截图.因为有一些IO操作,所以就很慢… 算法耗时 嘛,我这个算法是广度优先暴搜,应该比较慢. 点击间隔不统一 ↑这个形容不是很准确.好像,当两个有效的点被点击时,如果距离比较近,下次可以点击的时间间隔就比较短,反之亦然.只是推测,不太确定.因为试的时候,经常前面好多都没事,最后两三组点的时候出错,怀疑是排到最后的组一般距离比较远导致的结果.]]></content>
      <tags>
        <tag>碧蓝航线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Plus Ultra!]]></title>
    <url>%2Fbokuhiro-movie%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>动漫</category>
      </categories>
      <tags>
        <tag>动漫</tag>
        <tag>我的英雄学院</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[碧蓝航线翻牌小游戏复现]]></title>
    <url>%2Fblhx-fanpai%2F</url>
    <content type="text"><![CDATA[git repo:https://github.com/HHHHhgqcdxhg/azurlane-fanpai已部署在:https://blog.purecucumber.club/azurlane-fanpai/dist/index.html 一下午撸出来的web复现的碧蓝航线翻牌小游戏.一路写下来没遇到坑,但也没考虑性能.]]></content>
      <categories>
        <category>碧蓝航线</category>
      </categories>
      <tags>
        <tag>碧蓝航线</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩游戏 还愿]]></title>
    <url>%2Fdevotion%2F</url>
    <content type="text"><![CDATA[真的吓人…变写博客边玩吧. 游戏过程 小女孩透过墙洞看爸爸撕写的字…想了想,以后写代码错到恼羞成怒了也只注释不删 弹珠迷宫真是绝了 被老婆追杀那里吓坏了.用手挡住屏幕看不到主要画面,然后一直都不知道要转头跑…回头翻了别人的视频才知道要跑… 拔舌头那里真心不敢看…依旧拿手遮屏幕 评价第一次玩恐怖游戏来着,因为跟风就去玩了,吓得不轻.还是不喜欢这种,为恐怖而恐怖的游戏.里面的一些价值观也不认同. 凉凉2019年2月23日更新自断财路的傻逼玩意]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win32按键码]]></title>
    <url>%2Fvkcode%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147VK_CODE = &#123; 'backspace': 0x08, 'tab': 0x09, 'clear': 0x0C, 'enter': 0x0D, 'shift': 0x10, 'ctrl': 0x11, 'alt': 0x12, 'pause': 0x13, 'caps_lock': 0x14, 'esc': 0x1B, 'spacebar': 0x20, 'page_up': 0x21, 'page_down': 0x22, 'end': 0x23, 'home': 0x24, 'left_arrow': 0x25, 'up_arrow': 0x26, 'right_arrow': 0x27, 'down_arrow': 0x28, 'select': 0x29, 'print': 0x2A, 'execute': 0x2B, 'print_screen': 0x2C, 'ins': 0x2D, 'del': 0x2E, 'help': 0x2F, '0': 0x30, '1': 0x31, '2': 0x32, '3': 0x33, '4': 0x34, '5': 0x35, '6': 0x36, '7': 0x37, '8': 0x38, '9': 0x39, 'a': 0x41, 'b': 0x42, 'c': 0x43, 'd': 0x44, 'e': 0x45, 'f': 0x46, 'g': 0x47, 'h': 0x48, 'i': 0x49, 'j': 0x4A, 'k': 0x4B, 'l': 0x4C, 'm': 0x4D, 'n': 0x4E, 'o': 0x4F, 'p': 0x50, 'q': 0x51, 'r': 0x52, 's': 0x53, 't': 0x54, 'u': 0x55, 'v': 0x56, 'w': 0x57, 'x': 0x58, 'y': 0x59, 'z': 0x5A, 'numpad_0': 0x60, 'numpad_1': 0x61, 'numpad_2': 0x62, 'numpad_3': 0x63, 'numpad_4': 0x64, 'numpad_5': 0x65, 'numpad_6': 0x66, 'numpad_7': 0x67, 'numpad_8': 0x68, 'numpad_9': 0x69, 'multiply_key': 0x6A, 'add_key': 0x6B, 'separator_key': 0x6C, 'subtract_key': 0x6D, 'decimal_key': 0x6E, 'divide_key': 0x6F, 'F1': 0x70, 'F2': 0x71, 'F3': 0x72, 'F4': 0x73, 'F5': 0x74, 'F6': 0x75, 'F7': 0x76, 'F8': 0x77, 'F9': 0x78, 'F10': 0x79, 'F11': 0x7A, 'F12': 0x7B, 'F13': 0x7C, 'F14': 0x7D, 'F15': 0x7E, 'F16': 0x7F, 'F17': 0x80, 'F18': 0x81, 'F19': 0x82, 'F20': 0x83, 'F21': 0x84, 'F22': 0x85, 'F23': 0x86, 'F24': 0x87, 'num_lock': 0x90, 'scroll_lock': 0x91, 'left_shift': 0xA0, 'right_shift ': 0xA1, 'left_control': 0xA2, 'right_control': 0xA3, 'left_menu': 0xA4, 'right_menu': 0xA5, 'browser_back': 0xA6, 'browser_forward': 0xA7, 'browser_refresh': 0xA8, 'browser_stop': 0xA9, 'browser_search': 0xAA, 'browser_favorites': 0xAB, 'browser_start_and_home': 0xAC, 'volume_mute': 0xAD, 'volume_Down': 0xAE, 'volume_up': 0xAF, 'next_track': 0xB0, 'previous_track': 0xB1, 'stop_media': 0xB2, 'play/pause_media': 0xB3, 'start_mail': 0xB4, 'select_media': 0xB5, 'start_application_1': 0xB6, 'start_application_2': 0xB7, 'attn_key': 0xF6, 'crsel_key': 0xF7, 'exsel_key': 0xF8, 'play_key': 0xFA, 'zoom_key': 0xFB, 'clear_key': 0xFE, '+': 0xBB, ',': 0xBC, '-': 0xBD, '.': 0xBE, '/': 0xBF, ';': 0xBA, '[': 0xDB, '\\': 0xDC, ']': 0xDD, "'": 0xDE, "`": 0xC0&#125; win32按键码.留着一份省着每次再找了]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[碧蓝航线翻牌游戏脚本]]></title>
    <url>%2Fblhx-fanpai4-45%2F</url>
    <content type="text"><![CDATA[匹配相同的牌时是裁下每张牌后,直接对比每张图片的数组是否相同翻牌的时候想要同时点两张牌,但是查了下adb好像没有支持mult touch,然后想到在模拟器上给每个牌的位置设置快捷键,翻牌的时候调用win32api点击对应的快捷键来翻牌.最终成绩4.45秒.b站视频:https://www.bilibili.com/video/av44287472/ 下面是完整代码.其中vkcode.VK_CODE是win32按键码映射表,在这篇博客有82~89行那些几个sleep的参数是试出来的,再小就容易出错了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#! /usr/bin/env python# -*- coding: utf-8 -*-import timeimport osimport cv2import numpy as npimport win32apiimport win32confrom vkcode import VK_CODEclass Blhx: def __init__(self, adbPATH, sharedPATH): self.adb = adbPATH self.sharedPATH = sharedPATH def getScreen(self, filePath="/sdcard/Pictures/tmp.png"): os.system(f"&#123;self.adb&#125; -e shell screencap -p &#123;filePath&#125;") time.sleep(0.5) return cv2.imread(f"&#123;self.sharedPATH&#125;\\tmp.png") def tap(self, X, Y): os.system(f"&#123;self.adb&#125; -e shell input tap &#123;X&#125; &#123;Y&#125;") def cutEvery(self, img): ims = [] matched = [] for y in range(3): for x in range(6): startX = 148 * x + 238 startY = 162 * y + 179 endX = startX + 90 endY = startY + 129 im = img[startY:endY, startX:endX, :] thisImInfo = (y, x, im) hasmatch = False for i, imgInfo in enumerate(ims): difference = cv2.subtract(im, imgInfo[2]) result = not np.any(difference) if result: hasmatch = True matched.append(imgInfo[:2]) matched.append(thisImInfo[:2]) del ims[i] continue if not hasmatch: ims.append(thisImInfo) return matchedkeyboardsMap = [ "QWERTY".lower(), "ASDFGH".lower(), "ZXCVBN".lower()]def mian(): blhx = Blhx(r"E:\programfiles\adb\adb.exe", "J:\ldmnqshare") blhx.tap(800, 485) time.sleep(1.1) print("jietu") im = blhx.getScreen() pos = blhx.cutEvery(im) ks = [] for i, p in enumerate(pos): k = keyboardsMap[p[0]][p[1]] ks.append(k) kl = ks.__len__() if not kl == 18: print("没匹配好") return time.sleep(1) for x in range(9): k0 = 2 * x k1 = k0 + 1 kNode0 = ks[k0] kNode1 = ks[k1] win32api.keybd_event(VK_CODE[kNode0], 0, 0, 0) time.sleep(0.04) win32api.keybd_event(VK_CODE[kNode1], 0, 0, 0) time.sleep(0.04) win32api.keybd_event(VK_CODE[kNode0], 0, win32con.KEYEVENTF_KEYUP, 0) time.sleep(0.04) win32api.keybd_event(VK_CODE[kNode1], 0, win32con.KEYEVENTF_KEYUP, 0) print("tap") time.sleep(0.375)if __name__ == '__main__': mian()]]></content>
      <categories>
        <category>碧蓝航线</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>碧蓝航线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cuclasses]]></title>
    <url>%2FCuclasses%2F</url>
    <content type="text"><![CDATA[介绍Cuclasses是我正在写的python库,内容是集合了一些常用的类和方法 项目地址pypi(少有更新):https://pypi.org/project/cuclasses/github:https://github.com/HHHHhgqcdxhg/cuclasses 模块cuclasses.DottableDict顾名思义,能用 “.” 访问的dict.因为喜欢js访问对象属性的方式,可以用下标,也可以用点. cuclasses.singleton装饰器.被装饰的类为单例模式 cuclasses.CallableDict可以调用的dict,调用时返回自身. cuclasses.StrKeyDict在查询时把非字符串键转换为字符串的dict cuclasses.headerCopy2Dict因为在复制chrome开发者工具network里请求的header时很不方便,就弄了这个…把chrome里的headers复制进去,会转换成字典 123456789101112headerStr = """Accept: application/json, text/plain, */*Accept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.9Connection: keep-aliveCookie: l=v; buvid3=08DBF55E-086D-4BE2-9FCB-4B60BFA5F05A140254infocHost: message.bilibili.comOrigin: https://www.bilibili.comReferer: https://www.bilibili.com/video/av9912938/?p=11User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36"""a = headerCopy2Dict(headerStr)print(a)#&gt;&gt;&gt; &#123;'Accept': 'application/json, text/plain, */*', 'Accept-Encoding': 'gzip, deflate, br', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Host': 'message.bilibili.com', 'Origin': 'https://www.bilibili.com', 'Referer': 'https://www.bilibili.com/video/av9912938/?p=11', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'&#125; cuclasses.timePrint上下文管理器.带时间戳的print.随时可指定时间格式 12345678910111213141516with timePrint() as print: print(0) # &gt;&gt;&gt; [2019-02-10 16:23:35] 0 print(1, strf="[%Y-%m-%d %H:%M:%S]1") # &gt;&gt;&gt; [2019-02-10 16:23:35]1 1with timePrint("[%Y-%m-%d %H:%M:%S]2") as print: print(2) # &gt;&gt;&gt; [2019-02-10 16:23:35]2 2 print(3, strf="[%Y-%m-%d %H:%M:%S]3") # &gt;&gt;&gt; [2019-02-10 16:23:35]3 3print(4)# &gt;&gt;&gt; 4 cuclasses.timeCount装饰器.接受两个参数.被装饰的函数将在执行后打印执行时间 12:param enable: 设为False则不计时,直接执行函数:param method: 可选择的计时所用的获取时间的函数.默认time.perf_counter,或者也可以选填time.time,python3.7可以按需选用time.perf_counter_ns 1234567@timeCount()def bar(): print(&#123;"a": "c"&#125;)bar()#&gt;&gt;&gt; &#123;'a': 'c'&#125;#&gt;&gt;&gt; func bar excuted in : 6.044444444444444e-05 cuclasses.Downloader下载器. 1234:param directory:下载到的目录:param urls:需要下载的资源目录:param threads:并行下载的线程数:param headers:请求头,默认为&#123;&quot;user-agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36&quot;&#125; with open("xx.json","r") as f: data = json.load(f) d = Downloader(directory=r"E:\ACG\comic\general\どうして私が美術科に",urls=data) d.downloadAll()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本站的搭建]]></title>
    <url>%2Fbuild-blog%2F</url>
    <content type="text"><![CDATA[依赖本博客基于Hexo生成,选用Next.Mixins作为主题 正文主题不是很喜欢黑黑的颜色,就把css里颜色改了改,改成了蓝色的主题 写作工具VSC + MPE写md不要太爽(atom,sublime应该一样) 图床图床用的是七牛云上传图片至图床的工具是PicGo,同样不要太爽现在是vs-picgo了,爽上加爽 deploy不是很清楚hexo clean和hexo generate的关系,索性每次deploy的时候都先hexo clean再hexo g再hexo d.因为很麻烦,就写了段C++做成个exe int main() { system("hexo clean"); system("hexo g"); system("hexo d"); return 0; } 之后就把编译出来的exe命名为d.exe放到项目根目录,之后每次deploy就./d就完事了 评论之前选用的livere,现在换成了Valine]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ｆｔｐ 三 次 握 手]]></title>
    <url>%2FsomeFTP%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>无厘头</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[azurlane-painting开发笔记]]></title>
    <url>%2Fazurlane-painting%2F</url>
    <content type="text"><![CDATA[dalao的开发过程 我的开发过程 repo : https://github.com/HHHHhgqcdxhg/azurlane-painting图片处理过程: 将图片缩小 -&gt; 将图片色彩聚类到16色 -&gt; 将聚类后的16色归到舰b指定的8色 -&gt; 合成画板图片]]></content>
      <categories>
        <category>碧蓝航线</category>
      </categories>
      <tags>
        <tag>碧蓝航线</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bilibili机器人更新日志]]></title>
    <url>%2Fbili-bot-release-log%2F</url>
    <content type="text"><![CDATA[19/02/18 取消对以关键字”【お知らせ”开头的推特的图片打水印(那个图太小了) 19/02/07 取消对以关键字”【接続障害”开头的推特的转推(即日服服务器故障和故障修复的推文) 19/01/27 增加图片水印 18/12/24 修复IOS端点开大图一直正在加载的问题 18/12/21 自动在回复中发送机翻 18/12/20 取消对以关键字”【メンテナンス”开头的推特的转推(即日服维护说明) 18/12/19 䒕黃苽机器人开始运行]]></content>
      <categories>
        <category>bot</category>
      </categories>
      <tags>
        <tag>bot</tag>
        <tag>bilibot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[䒕黃苽B博碧蓝航线日推转发机器人README]]></title>
    <url>%2Fbili-bot-help%2F</url>
    <content type="text"><![CDATA[00010100101还什么都没有哦~]]></content>
      <categories>
        <category>bot</category>
      </categories>
      <tags>
        <tag>bot</tag>
        <tag>bilibot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小黄瓜机器人使用指南]]></title>
    <url>%2Fbot-help%2F</url>
    <content type="text"><![CDATA[介绍小黄瓜机器人QQ:2482513293想要自己的群拥有小黄瓜的话不用打招呼,直接拉就好哦小黄瓜详细功能列表见下文所有可能烦人的功能都是可以群管理发送指令开启/关闭的想要做一个跟小黄瓜类似的机器人,可以跳转至技术相关 加群准则因为加群太多会使服务器负担太大,所以会控制加群数量.不乐意加入的群: 人数比较少的群.因为百十个人及以下的群难以保证管理和群员的素质 不感兴趣的群.舰b群和kirara fantasia群以外的邀请不出意外应该不会接受 功能列表:1. 无指令功能:点击功能跳转到对应位置 功能 机器人需要管理权限 控制开关 转发推特功能 否 !tweetConfig指令 复读机随机禁言功能 ==是== !fuduBanConfig指令 新人入群提醒功能 否 !welcomeConfig指令 2. 指令功能:指令功能是通过发送以感叹号开始的指令触发的功能,中文或英文感叹号均可,无视大小写.点击功能跳转到对应位置 指令 功能 机器人需要管理权限 限管理可用 控制开关 !help 帮助功能 否 否 无 !fuck 众裁功能 ==是== 否 指令 !sleep 金质睡眠功能 ==是== 否 指令 !del 定时撤回消息功能 ==是== 否 指令 !recipe 获取一份假的食谱功能 否 否 指令 !build 碧蓝航线建造模拟器 否 否 指令 !tweetConfig 设置转发推特的功能 否 ==是== 无 !enable 开启功能的功能 否 ==是== 无 !disable 关闭功能的功能 否 ==是== 无 !report 联系主人功能 否 ==是== 无 功能详情新人入群提醒功能!welcomeConfig指令限管理可用 有新人入群时,小黄瓜机器人将@新人,发送入群提醒管理可通过发送 !welcomeConfig + 内容 来指定入群提醒内容如:12!welcomeConfig欢迎加入善良可爱小海豹保护者协会群!请先阅读群置顶公告哦! 注: 设置的入群提醒不宜太长,避免刷屏.建议提醒阅读群公告,内容写在群公告即可 设置的入群提醒中的图片将被忽略 !welcomeConfig后不跟内容,将取消入群提醒 复读功能通过指令开/关功能 小黄瓜检测到有人在复读,就会跟着复读因不堪网络暴力机器人发消息太多会被腾讯制裁,本功能停止使用 复读机随机禁言功能!fuduBanConfig指令限管理可用 | 机器人需要管理权限 管理可通过发送类似下面的消息,更改禁言复读机配置1234567!fuduBanConfig&#123; &quot;banLen&quot;: 2, &quot;banMult&quot;: 10, &quot;banRebel&quot;: false, &quot;randMemberMode&quot;: 2, &quot;randTimeMode&quot;: 3&#125; 对配置的解释如下: 字段名描述可选值对应效果banLen触发复读禁言条数&gt;= 2复读条数(算上 被复读的那一条) 大于等于 这个值时,触发复读禁言banMult禁言力度&gt;= 1控制禁言时长的力度banRebel是否开启禁言复读机叛徒true此时,如果是参与复读的人打断复读,则不再进行复读机随机抽取,而是直接抽中这名复读机叛徒false正常进行复读机抽取randMemberMode抽取复读机的模式0关闭本功能,不再禁言复读机1随机抽取一名复读机2正态分布随机抽取一名复读机3取倒数第二个复读机randTimeMode抽取禁言时长的模式1经典随机,禁言时间为 (1~本轮复读条数 之间的随机数) banMult2复读总长相关,禁言时间为 本轮复读条数 banMult3固定时长,禁言时长为 banMult4按座位,被抽到的复读机在本轮复读中是倒数第n个,时长就为 n * banMult 众裁功能本功能为指令功能,通过发送 !fuck + @一名群员 触发 通过指令开/关功能 | 机器人需要管理权限 在一人通过该指令开启对一名群员A的众裁之后,将开始三分钟的计时,统计三分钟内通过该指令参与对群员A的众裁的人数,于三分钟后对群员A进行制裁(禁言)禁言时长: 参与本轮众裁人数 禁言时长(分钟) &lt;= 2 不禁言 3 5 4 10 >= 5 每多一人,时长加2 注: !fuck后面跟上@一名群员,这个@必须是能@到人的,复制粘贴的不管用 不要重复参与众裁,否则会被禁言1分钟 不要再众裁群主管理辣! 不要欺负人哦,拿来制裁海豹正适合 定时撤回消息功能本功能为指令功能,通过发送 !del + 时长 + 空格 + 消息 触发 通过指令开/关功能 | 机器人需要管理权限 示例:1!del 10 这条消息将在10秒后被撤回 注: 如 !del 后不加时长,直接跟消息,则默认撤回时长为5秒 如设置时长,记得时长数字和后面消息中间用空格分隔 设置时长最大为600,超过这个值将改为5 本功能为限 非管理群员 使用 金质睡眠功能本功能为指令功能,通过发送 !sleep 触发 通过指令开/关功能 | 机器人需要管理权限 22:00~次日03:59发送指令,发送者将被禁言6小时 食谱功能本功能为指令功能,通过发送 !recipe 或 !gbf触发 通过指令开/关功能 | 消耗黄瓜片 : 20 发送一份分享,标题和图片为随机食谱的标题和图片,点开却是granbluefantasy.jp 碧蓝航线建造模拟器本功能为指令功能,通过发送 !build 触发 通过指令开/关功能 | 消耗黄瓜片 : 40 !build可接受最多两个正整数参数,用逗号分隔(中英文标点均可) 指令 效果 !build 抽取1池10次 !build x 抽取x池10次,x可为1,2,3 !build x,y 抽取x池y次,y为1~10 注: 概率保证按照官方给出的概率 卡池信息来自碧蓝航线wiki建造模拟器 不准备做限时建造的卡池,想玩的请移步碧蓝航线wiki限时建造模拟器 本功能需要生成图片发送图片,对服务器资源消耗过大,不要玩太过分哦 转发推特功能!tweetConfig指令限管理可用小黄瓜会实时(Real Time)转发指定推特用户发送的新推特至qq群新加的群是不会转发推特的,需要经过设置后,可转发指定推特设置方法:发送类似如下的消息,可添加或修改推特转发: 12345678910111213!tweetConfig&#123; &quot;follow&quot;:&#123; &quot;name&quot;:&quot;@azurlane_staff&quot;, &quot;nickName&quot;:&quot;碧蓝航线日服推特&quot; &#125;, &quot;groupInfo&quot;: &#123; &quot;nickName&quot;: &quot;在这里填写群名&quot;, &quot;trans&quot;: false, &quot;sendRT&quot;: false, &quot;mediaOnly&quot;:false, &quot;follow&quot;: true &#125;&#125; 以下为对上面配置的解释:12345678910111213!tweetConfig&#123; &quot;follow&quot;:&#123; &quot;name&quot;:&quot;这里填入需要关注的人的推特Id,以@开头&quot;, &quot;nickName&quot;:&quot;这里填入关注的人的称呼&quot; &#125;, &quot;groupInfo&quot;: &#123; &quot;nickName&quot;: &quot;群名&quot;, //在这里填写群名,理论上随便填,主要目的是让作者辨识出是哪个群 &quot;trans&quot;: true, //是否需要发送一遍将经过百度翻译的推文,把true改成false将不翻译 &quot;sendRT&quot;: false, //是否需要发送 转发和回复别人的推特,建议关闭,打开很烦人的,把false改成true打开 &quot;mediaOnly&quot;: false, //将false改成true,将只发有图片内容的推特,纯文字推特将忽略,适合关注画师 &quot;follow&quot;: true //将true改为false,将不转发此人的推特 &#125;&#125; 注意: 这条消息除开头的!tweetConfig以外,全部大小写敏感且必须用半角标点符号(即英文标点) 大括号,冒号,逗号,引号都不能漏 不要将true打成ture,false打成flase… 若出现”查找用户信息失败”提示,请确定关注的人的id以@符号开头,确认无误后稍后再试 小黄瓜机器人定时每周四取消对 只有一个群关注的推特 的关注 附录中给出了些常用推特供参考 开启功能的功能本功能为指令功能,通过发送 !enable + 其他功能指令 触发 限管理可用 指令 功能 !enable !sleep 开启金质睡眠功能 !enable !fuck 开启众裁功能 !enable !recipe 开启食谱功能 !enable !build 开启碧蓝航线建造模拟器 !enable !del 关闭定时撤回消息功能 注:无视所有感叹号全/半角,不区分大小写 关闭功能的功能本功能为指令功能,通过发送 !disable + 其他功能指令 触发 限管理可用 指令 功能 !disable !sleep 关闭金质睡眠功能 !disable !fuck 关闭众裁功能 !disable !recipe 关闭食谱功能 !disable !build 关闭碧蓝航线建造模拟器 !disable !del 关闭定时撤回消息功能 注:无视所有感叹号全/半角,不区分大小写 联系主人功能本功能为指令功能,通过发送 !report 触发 !report指令限管理可用机器人接收到以!report开头的消息,会发送给主人看到注: 乱玩此功能会打扰到主人的,请不要乱玩 机器人功能相关请先仔细阅读本篇文档对应部分 在群里直接@小黄瓜机器人,主人一般情况下看不到的 私聊小黄瓜机器人,主人一般情况下看不到 使用!report指令的消息,主人会看到,并尽量及时回应 按照下面联系方式联系主人,是比较有效的联系方式 有事请直接说事,免掉”在吗”之类的打招呼内容 谢绝无事骚扰 &nbsp;&nbsp;&nbsp;ex. 不过如果你有色图,请务必私发给䒕黃苽机器人 主人QQ:2894700792 加好友的认证信息请认真填写 黄瓜片系统出于目的: 防止功能滥用对小黄瓜服务器造成太大负担 防止某些功能造成刷屏 防止被tx限制 现在实装黄瓜片系统,某些功能需要消耗黄瓜片(黄瓜片就是类似体力的东西啦) 获得黄瓜片小黄瓜机器人会在每天凌晨04:30,中午13:30,晚上19:30将所有群友的黄瓜片置为40点.即,黄瓜片不可积攒,每个时间段40点 消耗黄瓜片消耗黄瓜片的功能 功能 消耗黄瓜片数/次 碧蓝航线建造模拟器 40 食谱功能 20 其他小黄瓜机器人的管理权限给小黄瓜管理权限后,机器人并不能马上意识到自己是管理,需要重启插件,这时通过联系主人功能告知重启 限管理可用功能本文中的”管理”,皆指 管理or群主把部分功能做成仅限管理可用,目的是过滤掉没素质的人,希望身为管理能意识到自己的一份素质,不要闲来无事report玩,或者凭一己之见关注一些奇怪或无聊的推特 idea相关有觉得好玩的机器人的玩法的想法,可以联系主人哦 技术相关因为小黄瓜机器人项目中有很多小黄瓜的apikey和OAuth认证信息,开源很麻烦,所以闭源小黄瓜机器人项目代码是使用python编写,通过richardchien/coolq-http-api和richardchien/python-aiocqhttp控制酷Q实现的,监听新推特是通过tweepy.StreamListener实现酷Q只能跑在windows或有图形界面的linux服务器上,本人使用的服务器是阿里云服务器的学生机 其他的䒕黃苽 䒕黃苽bilibili机器人:@碧蓝航线转推姬会将碧蓝航线新日推转发到B站动态,并在评论区附上翻译䒕黃苽B博机器人介绍 䒕黃苽微博机器人:@碧蓝航线转推姬(和B站的同名哦)会将碧蓝航线新日推转发到微博 其他相关希望群友们素质聊天 投喂喜欢小黄瓜机器人的话可以支付宝投喂哦 免费红包哦 打赏¥1 打赏¥3 打赏¥10 打赏一单 每天都能扫一次哦 老冰棍 快乐水 一餐饭 老婆 附录:常用推特id 推特id 备注 @korindo 博丽神主推特 @kirarafantasia 芳文社手游きららファンタジア官推 @azurlane_staff 碧蓝航线日服官推 @azurlanekorea 碧蓝航线韩服官推 @AzurLane_EN 碧蓝航线美服官推 @KanColle_STAFF 「艦これ」開発/運営 @fgoproject FGO官推 @granbluefantasy 学习资料]]></content>
      <categories>
        <category>bot</category>
      </categories>
      <tags>
        <tag>qqbot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python程序打包成exe]]></title>
    <url>%2Fpy2exe%2F</url>
    <content type="text"><![CDATA[前言用python写了个项目(在这)想发布出去给没有python环境的人用.试了pyinstaller,打包出来不能正常跑…于是心生淫技,将python环境跟项目放到一起,然后拿C++写几行程序,通过system call的方式调用python运行项目脚本,再将这个C++程序编译成exe… python环境的准备我首先试了拿虚拟环境,然后发现虚拟环境少了一堆dll…拿自己的python环境吧,一堆这个项目用不着的库,打包进去太大,挑出来太麻烦…索性另外装一个python.我本身环境是3.6.7版本的,又去另外装了个3.7.2版本.安装时注意把什么设置环境变量,向所有用户安装都取消了,留着pip就好,之后拿pip把包都装好,然后把整个python目录拷贝到项目根目录就完事了 准备一个exe这就比较野蛮…程序入口12345678910111213141516171819202122```C++#include &lt;iostream&gt;#include &lt;windows.h&gt;#include &lt;direct.h&gt; using namespace std;int main(int argc, char * argv[])&#123; string cwd = _getcwd(NULL, 0); string cmd = &quot;\\Python37-32\\python.exe __main__.py&quot;; cmd = cwd + cmd; for (int i = 1; i &lt; argc; i++) &#123; cmd += &quot; &quot;; cmd += argv[i]; &#125; const char *cmd_c_str = cmd.c_str(); // cout &lt;&lt; cmd_c_str&lt;&lt;endl; system(cmd_c_str); //system(&quot;pause&quot;); return 0;&#125; 编译好拿出来放到项目根目录就完事了]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桌面追番助手]]></title>
    <url>%2FbangumiDesktopAssistant%2F</url>
    <content type="text"><![CDATA[本项目git仓库:https://dev.tencent.com/u/hhhhhg/p/bangumiDesktopAssistant尝试了打包成exe却做不到,所以应该只有装了python才能用了XDpython版本是3.6.4(因为用到了f前缀字符串,所以大概需要至少3.6版本),操作系统只试了windows 使用:1234git clone https://git.dev.tencent.com/hhhhhg/bangumiDesktopAssistant.gitcd bangumiDesktopAssistantpip install -r requirements.txtpython __main__.py 在任务栏找到图标(和项目头像是同一张图片),右键可进行追番编辑或者退出程序.追番编辑工具按要求填入信息,可生成一份番剧信息,保存在src/db/bangumisInfo中,如果填入得当,不发生意外,则可正常使用.遇到特殊情况(比如番剧停更)则需要手动改对应的json文件中的chapters部分… 有番剧更新时,会播放音频,为src/audio/alarm.wav透明度,配色等配置存在src/db/config.json中,可以轻易更改 配置好环境后,之后可以运行bangumi.bat来运行本工具,也可在注册表中将bangumi.bat设为开机自启运行截图: 1080p屏幕下unfocused状态表现 1080p屏幕下focused状态(鼠标悬停在之上时)表现 之前用tkinter写了两天了,察觉有点不好用,又换成了PyQt5.耗资源方面,平常在后台运行就占用十几二十M内存]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>gui</tag>
        <tag>动漫</tag>
      </tags>
  </entry>
</search>
